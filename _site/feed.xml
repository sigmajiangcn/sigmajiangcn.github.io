<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>进无止境</title>
    <description>专注数学，机器学习和数据挖掘应用
</description>
    <link>http://sigmajiangcn.github.io/</link>
    <atom:link href="http://sigmajiangcn.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 28 Jan 2018 18:04:51 +0800</pubDate>
    <lastBuildDate>Sun, 28 Jan 2018 18:04:51 +0800</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>放眼未来之一:区块链</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;前言&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;回收硬盘空间&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;前言&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;最近公司金融学院组织 《金融黑科技－与大牛一起解码区块链》，多位嘉宾针对区块链技术做了一些分享。思想碰撞，收获很多。&lt;/p&gt;

&lt;p&gt;与人工智能、云计算不同，区块链是最新十年来唯一诞生于&lt;strong&gt;草根&lt;/strong&gt;的重大技术。区块链是一种防篡改、共享的、可追溯的分布式账本技术（DLT）。比特币网络里，每十分钟诞生一个新的区块，区块里打包了网络里最近十分钟产生的交易。由某一个矿工做hash运算产生这个区块，通过共识算法，同步到其他矿工节点去。&lt;/p&gt;

&lt;p&gt;去年有些区块链相关的大会还需要嘉宾用一句话阐述区块链，说明区块链还处在概念澄清的阶段。但是很多颠覆性的革命技术，在指数式爆发之前，很多人高估了其短期的影响，而低估了长期的影响。&lt;/p&gt;

&lt;p&gt;区块链是一个能&lt;strong&gt;制造信用&lt;/strong&gt;的机器，是从&lt;strong&gt;信息&lt;/strong&gt;互联网转向&lt;strong&gt;价值&lt;/strong&gt;互联网的重要途径。下面以比特币作者&lt;strong&gt;Satoshi Nakamoto&lt;/strong&gt;的&lt;a href=&quot;https://bitcoin.org/bitcoin.pdf&quot;&gt;论文&lt;/a&gt;为核心，针对其关键技术进行分析。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;持续更新&lt;/strong&gt;
## 比特币
一种点对点的电子现金系统。完全点对点的电子现金系统可以不通过金融机构，由一方直接发送在线支付给另一方。
### 交易
我们将电子货币定义为一串由数字签名组成的链条。每一个电子货币的持有者通过下面的方式将它转移给下一位所有者：
- 对前一个交易和下一位所有者的公钥签署一个数字签名；
- 将这个签名附加在交易的末尾；
- 收款人通过验证签名，就可以验证电子货币的所有者链条。
### 时间戳服务器
时间戳服务器通过对交易事件构成的区块进行哈希计算，从而位区块打上时间戳，并且广播该哈希值。后续的时间戳都对之前的一个事件戳进行增强，从而形成了一个链条。
### 工作量证明
这是区块链分布式共识的共识。时间戳网络完成工作量证明的过程是：
- 在区块中添加一项随机数
- 变换随机数，直到找到一个值，使区块的哈希值出现被要求数目的零。&lt;/p&gt;

&lt;p&gt;目前有多种共识的，并不统一。
### 网络
节点总是认为最长链就是正确的链条，并持续在它的基础上工作以延长它。
### 激励&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;回收硬盘空间&lt;/h3&gt;
&lt;p&gt;### 简化支付确认
### 价值的组合与分割
### 隐私
### 计算
$p=$ 诚实节点发现下一个区块的概率
$q=$ 攻击者发现下一个区块的概率
$q_z=$ 攻击者最终消弭了$z$ 个区块的落后差距
$q_z=$&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
q_z=
\begin{equation}  
\left\{  
             \begin{array}{lr}  
             1  ,p \leq q \\
             (q/p)^z,p&gt;q &amp;
      \end{array}
\right.  
\end{equation} %]]&gt;&lt;/script&gt;
## 量子计算
量子计算机如果打破了区块链的平衡后，应该怎么办？
### 总结
“工欲善其事，必先利其器”。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;参考文献&lt;/h2&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Sun, 28 Jan 2018 12:43:06 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/future/2018/01/28/Future-Blockchain.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/future/2018/01/28/Future-Blockchain.html</guid>
        
        
        <category>Future</category>
        
      </item>
    
      <item>
        <title>数据分析工具之五:Spark</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;文件交互&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;并行计算&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;常用算子&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;其他常用点&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[TOC]
## 前言
Spark是一个高效内存迭代计算的模型训练框架。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;持续更新&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;文件交互&lt;/h2&gt;

&lt;h2 id=&quot;section-1&quot;&gt;并行计算&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;PARALLEL&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;常用算子&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Transformation
Transformation 操作是延迟计算的，也就是说从一个RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Action
Action 算子会触发 Spark 提交作业（Job），并将数据输出 Spark系统。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;map&lt;/li&gt;
  &lt;li&gt;flatMap&lt;/li&gt;
  &lt;li&gt;union&lt;/li&gt;
  &lt;li&gt;groupBy&lt;/li&gt;
  &lt;li&gt;filter&lt;/li&gt;
  &lt;li&gt;join&lt;/li&gt;
  &lt;li&gt;collect&lt;/li&gt;
  &lt;li&gt;count&lt;/li&gt;
  &lt;li&gt;reduce&lt;/li&gt;
  &lt;li&gt;aggregate&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;其他常用点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;自定义函数&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;“工欲善其事，必先利其器”。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;参考文献&lt;/h2&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 15 Dec 2017 21:12:06 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/tools/2017/12/15/DataAnalysis-Spark.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/tools/2017/12/15/DataAnalysis-Spark.html</guid>
        
        
        <category>Tools</category>
        
      </item>
    
      <item>
        <title>数据分析工具之四:Pig常用库</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;文件交互&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;并行计算&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;常用算子&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;其他常用点&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[TOC]
## 前言
Pig是一门脚本语言，易于入门，方便灵活，容易忘记。在进行模型样本准备时，比sql高效很多。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;持续更新&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;文件交互&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;load
&lt;code class=&quot;highlighter-rouge&quot;&gt;shell
xinwen_view = load &#39;$INPUT_PATH&#39; as (count:int, count_pv:int, count_kj:int)
&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;store
&lt;code class=&quot;highlighter-rouge&quot;&gt;shell
store b into &#39;$OUTPUT_PATH&#39;;
&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;并行计算&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;PARALLEL&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;常用算子&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;group&lt;/li&gt;
  &lt;li&gt;flatten&lt;/li&gt;
  &lt;li&gt;foreach&lt;/li&gt;
  &lt;li&gt;rmf&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;其他常用点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;自定义函数&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;“工欲善其事，必先利其器”。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;参考文献&lt;/h2&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 14 Dec 2017 21:12:06 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/tools/2017/12/14/DataAnalysis-Pig.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/tools/2017/12/14/DataAnalysis-Pig.html</guid>
        
        
        <category>Tools</category>
        
      </item>
    
      <item>
        <title>数据分析工具之三:R常用库</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;文件交互&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;并行计算&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;常用算子&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;其他常用点&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[TOC]
## 前言
R是一门统计学家语言，易于入门，方便灵活，容易忘记。尤其当掌握了一些常用的库，更是用的飞起。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;持续更新&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;文件交互&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;read.table&lt;/li&gt;
  &lt;li&gt;write.table&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;并行计算&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;foreach&lt;/li&gt;
  &lt;li&gt;doMC
registerDoMC&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;常用算子&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;dim&lt;/li&gt;
  &lt;li&gt;length&lt;/li&gt;
  &lt;li&gt;rbind&lt;/li&gt;
  &lt;li&gt;c&lt;/li&gt;
  &lt;li&gt;[]&lt;/li&gt;
  &lt;li&gt;seq&lt;/li&gt;
  &lt;li&gt;%%&lt;/li&gt;
  &lt;li&gt;ceiling&lt;/li&gt;
  &lt;li&gt;is.matrix&lt;/li&gt;
  &lt;li&gt;ts&lt;/li&gt;
  &lt;li&gt;tryCatch&lt;/li&gt;
  &lt;li&gt;data.frame&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;其他常用点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;forecast&lt;/li&gt;
  &lt;li&gt;dplyr&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;“工欲善其事，必先利其器”。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;参考文献&lt;/h2&gt;
</description>
        <pubDate>Wed, 13 Dec 2017 21:12:06 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/tools/2017/12/13/DataAnalysis-R.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/tools/2017/12/13/DataAnalysis-R.html</guid>
        
        
        <category>Tools</category>
        
      </item>
    
      <item>
        <title>数据分析工具之二:Python常用库</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;文件交互&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;常用算子&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;其他常用点&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[TOC]
## 前言
Python是一门常用的编程语言，易于入门，方便灵活。尤其当掌握了一些常用的库，更是用的飞起。这里主要介绍介绍Pandas。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;持续更新&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;文件交互&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;read_csv
&lt;code class=&quot;highlighter-rouge&quot;&gt;python
df=pd.read_csv(train_file,sep=&quot;,&quot;,index_col=target_list,nrows=5)
&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;to_csv&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;常用算子&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;query&lt;/li&gt;
  &lt;li&gt;groupby&lt;/li&gt;
  &lt;li&gt;merge&lt;/li&gt;
  &lt;li&gt;date_range&lt;/li&gt;
  &lt;li&gt;concat&lt;/li&gt;
  &lt;li&gt;reset_index&lt;/li&gt;
  &lt;li&gt;sort_values
&lt;code class=&quot;highlighter-rouge&quot;&gt;python
algo_filter_df=compare_df.groupby(target_list)[[&#39;algorithm&#39;,&#39;result&#39;]].apply(lambda x:pd.DataFrame.sort_values(x,by=&#39;result&#39;)[[&#39;algorithm&#39;]].head(2)).reset_index()
&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;lambda
&lt;code class=&quot;highlighter-rouge&quot;&gt;python
df.apply(lambda x:True if x.sum()&amp;gt;10 else &#39;false&#39;)
df[&#39;mean&#39;]=df.mean(axis=1)
df.query(&quot;mean&amp;gt;10&quot;).drop([&#39;mean&#39;],axis=1)
&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;fillna&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;drop del
drop 删除列返回新的df，不影响原有数据，更安全&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;loc、iloc、ix
&lt;code class=&quot;highlighter-rouge&quot;&gt;python
df.head(2).iloc[:,0:1]
&lt;/code&gt;
## matplotlib绘图&lt;/li&gt;
  &lt;li&gt;figure&lt;/li&gt;
  &lt;li&gt;hist&lt;/li&gt;
  &lt;li&gt;xlabel&lt;/li&gt;
  &lt;li&gt;ylabel&lt;/li&gt;
  &lt;li&gt;legend&lt;/li&gt;
  &lt;li&gt;show&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;其他常用点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;glob&lt;/li&gt;
  &lt;li&gt;os.makedirs&lt;/li&gt;
  &lt;li&gt;os.sys.platform.startswith(“win”)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;“工欲善其事，必先利其器”。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;参考文献&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 12 Dec 2017 21:12:06 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/tools/2017/12/12/DataAnalysis-Python.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/tools/2017/12/12/DataAnalysis-Python.html</guid>
        
        
        <category>Tools</category>
        
      </item>
    
      <item>
        <title>数据分析工具之一:Shell常用命令</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#grep&quot; id=&quot;markdown-toc-grep&quot;&gt;用grep查找日志问题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;单个文件字符串替换&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;两个文件合并&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;顺序执行&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[TOC]
## 前言
Shell是一门常用的脚本语言，易于入门，方便灵活。在数据处理时，尤其是处理日志时非常有帮助。常用的主要如Grep、awk、sed三大神器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;持续更新&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;grep&quot;&gt;用grep查找日志问题&lt;/h2&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;grep -R -n -A 5 -B 6 &lt;span class=&quot;s2&quot;&gt;&quot;error&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.log
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section&quot;&gt;单个文件字符串替换&lt;/h2&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sed -i &lt;span class=&quot;s2&quot;&gt;&quot;s/[()]//g&quot;&lt;/span&gt;   替换
sed  -i &lt;span class=&quot;s2&quot;&gt;&quot;1i&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\%&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;s&quot;&lt;/span&gt; %s   插入
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section-1&quot;&gt;两个文件合并&lt;/h2&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;awk -F&lt;span class=&quot;s2&quot;&gt;&quot;,&quot;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NR==FNR {a[$1]=$2} NR&amp;gt;=FNR{if(NF&amp;gt;5 &amp;amp;&amp;amp; $6 in a &amp;amp;&amp;amp; $5==a[$6]){b[$6]=$0}} END{for(i in b){print b[i]}}&#39;&lt;/span&gt; a b  &amp;gt;c
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section-2&quot;&gt;顺序执行&lt;/h2&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ps -ef |grep smart_server |awk &lt;span class=&quot;s1&quot;&gt;&#39;{print $2}&#39;&lt;/span&gt; |xargs &lt;span class=&quot;nb&quot;&gt;kill&lt;/span&gt; -9
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section-3&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;“工欲善其事，必先利其器”。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;参考文献&lt;/h2&gt;
</description>
        <pubDate>Mon, 11 Dec 2017 21:12:06 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/tools/2017/12/11/DataAnalysis-Shell.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/tools/2017/12/11/DataAnalysis-Shell.html</guid>
        
        
        <category>Tools</category>
        
      </item>
    
      <item>
        <title>时间序列分析</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;业务背景&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;算法简介&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;主要内容&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;基础知识&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;平稳性&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;相关性&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-6&quot; id=&quot;markdown-toc-section-6&quot;&gt;周期性&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-7&quot; id=&quot;markdown-toc-section-7&quot;&gt;模型识别&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#section-8&quot; id=&quot;markdown-toc-section-8&quot;&gt;相关函数法&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-9&quot; id=&quot;markdown-toc-section-9&quot;&gt;模型检验&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#section-10&quot; id=&quot;markdown-toc-section-10&quot;&gt;平稳性检验&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#section-11&quot; id=&quot;markdown-toc-section-11&quot;&gt;白噪声检验&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-12&quot; id=&quot;markdown-toc-section-12&quot;&gt;参数估计&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#mapmle&quot; id=&quot;markdown-toc-mapmle&quot;&gt;MAP与MLE相统一&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-13&quot; id=&quot;markdown-toc-section-13&quot;&gt;线性时间序列分析&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#ar&quot; id=&quot;markdown-toc-ar&quot;&gt;自回归模型AR&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#ma&quot; id=&quot;markdown-toc-ma&quot;&gt;滑动平均模型MA&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#arma&quot; id=&quot;markdown-toc-arma&quot;&gt;自回归滑动平均模型ARMA&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#arima&quot; id=&quot;markdown-toc-arima&quot;&gt;单位根非平稳性与ARIMA&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sarima&quot; id=&quot;markdown-toc-sarima&quot;&gt;季节模型与SARIMA&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-14&quot; id=&quot;markdown-toc-section-14&quot;&gt;非线性时间序列分析&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#lstm&quot; id=&quot;markdown-toc-lstm&quot;&gt;LSTM&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bptt&quot; id=&quot;markdown-toc-bptt&quot;&gt;BPTT反向传播算法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#forecast&quot; id=&quot;markdown-toc-forecast&quot;&gt;Forecast&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#facebook&quot; id=&quot;markdown-toc-facebook&quot;&gt;Facebook&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#ensemble&quot; id=&quot;markdown-toc-ensemble&quot;&gt;Ensemble&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-15&quot; id=&quot;markdown-toc-section-15&quot;&gt;下一步工作&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-16&quot; id=&quot;markdown-toc-section-16&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-17&quot; id=&quot;markdown-toc-section-17&quot;&gt;致谢&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-18&quot; id=&quot;markdown-toc-section-18&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;业务背景&lt;/h2&gt;
&lt;p&gt;品牌广告通常采用CPM业务模式，特点在于保价保量，需要我们准确预估各个广告位在未来一段时间的可用库存，以便合理售卖广告资源。通常，品牌广告提前14-28天下单占比接近60%，因此降低短期预估误差可以更好指导售卖；另外，游戏等行业客户普遍存在提前3个月下单，降低长期预估误差可以更好服务细分需求。&lt;/p&gt;

&lt;p&gt;通过分析腾讯视频在PC端、移动端、TV端最近三年的的库存数据，我们发现库存不仅在每周表现出$weekly$波动性（例如，双休日高于工作日），另外在每个月也表现出一定的$yearly$波动（例如，暑期比开学高，除夕前后比较低）。之前大部分业务有效数据积累不足两年，不能有效探索数据长期规律。因而难以捕捉到库存的季节变化，造成较高的预估偏差（例如暑期结束开学，如果没有考虑到开学季库存大幅下降的特性，会造成预估过高的现象；又如国庆之前预估的训练集为下降趋势，会造成国庆节预估过低的现象），往往需要人工干预来调整预估库存。&lt;/p&gt;

&lt;p&gt;近来，我们通过综合分析多个维度的长期数据，挖掘其中的长周期（全年各个月份的波动差异）以及阶段周期（暑假的$weekly$周期与非暑假有差异）等规律，从而进一步降低品牌广告的预估误差，取得了一定的效果，具体如下：
1. 提前14天的基线算法预估误差为10.2%，新算法预估误差为8.9%，预估误差同期下降12.7%；
2.  提前120天的基线算法预估误差为17.4%，新算法预估误差为13.7%，预估误差同期下降21.3%；&lt;/p&gt;

&lt;p&gt;通过对库存时间序列预估的分析，我们在多周期时间序列预估方面有了部分积累，对时间序列的平稳、趋势、周期、自回归等规律有了更多认识。在调研过程中，我们观察到在天气、电商、金融等各行各业都有挖掘时间序列的特性，预估未来走势，从而更好指导生产、分配以及投资等需求。“虽世殊事异，所以兴怀，其致一也”，我们通过总结梳理多方面文献与资料，试图对时间序列分析做一个简要的介绍，希望能够对相关场景预估有一定的帮助。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;算法简介&lt;/h2&gt;

&lt;p&gt;到了19世纪，概率论的发展从对（相对静态的）随机变量的研究发展到对随机变量的时间序列$s_1,s_2,s_3….s_t,…$,即随机过程（动态的）研究。在哲学的意义上，这是人类认识的一个飞跃。但是，随机过程要比随机变量复杂得多。首先，在任何一个时刻$t$，对应的状态$s_t$都是随机的。时间序列分析($Time\ Series\ Aanlysis,TSA$)是一种动态数据处理的统计方法。该方法基于随机过程理论和数理统计学方法，研究随机数据序列所遵从的统计规律用于解决实际问题。业界很多公司，都结合自己业务需求，分析时间序列的特性，借此来达到预测或者异常点检测的目的。&lt;/p&gt;

&lt;p&gt;2017年2月份，$Facebook$宣布开源了一款基于$Python$和$R$语言的时间序列预测工具—&lt;a href=&quot;https://facebook.github.io/prophet/&quot;&gt;$Prophet$&lt;/a&gt;，即”先知”。作者$Benjamin\ Letham$在对应的论文《$Forecasting\ at\ Scale$》中提到，提出$Prophet$的目的在于希望帮助大量的分析师在众多场景下解决大数据量下的时间预测问题，这就是”$at\ Scale$”的内涵。&lt;/p&gt;

&lt;p&gt;全球最大最优质的搜索引擎$Google$针对搜索量、收入等业务指标也有预估需求，在实际业务中采用多种模型集成提升预估精度。并且开源了基于贝叶斯结构化时间序列分析方法&lt;a href=&quot;https://www.rdocumentation.org/packages/bsts/versions/0.7.1/topics/bsts&quot;&gt;$bsts(Bayesian\ Structual\ Time\ Series)$&lt;/a&gt;。由于现实数据大部分是非平稳的，$Vitaly\ Kuznetsov$提出来基于差异量的&lt;a href=&quot;https://cs.nyu.edu/~mohri/talks/NIPSTutorial2016.pdf&quot;&gt;$“DBP”(Discrepancy\ based\ Forecast)$&lt;/a&gt;来预估非平稳时间序列序列也取得了良好的效果。&lt;/p&gt;

&lt;p&gt;在时间序列中，异常检测也是一个重要问题。$Twitter$号称”地球脉搏”,流量异常检测对其运营有着不小的挑战，其在2015年开源了一个$R$语言的算法包&lt;a href=&quot;https://github.com/twitter/AnomalyDetection&quot;&gt;$Anomaly\ Detection$&lt;/a&gt;借此，$Twitter$通常会在重大新闻和体育赛事期间扫描入站流量，发现那些使用僵尸账号发送大量垃圾（营销）信息的机器人。&lt;/p&gt;

&lt;p&gt;$Netflix$作为世界上最大的在线影片租赁服务商，拥有大量的服务器集群以支撑在线影片的存储以及个性化影片推荐等服务。其在2014左右开源了&lt;a href=&quot;https://github.com/Netflix/Surus&quot;&gt;$Robust\ Anomaly\ Detection$&lt;/a&gt;,借此，能自动发现“不健康”的服务器,快速修复问题，减轻运维人员的负担。&lt;/p&gt;

&lt;p&gt;我们最近对品牌广告的库存预估进行分析时，发现结合长周期可以有效捕捉时间序列的长周期变化规律，从而进一步提升库存预估精度。时间序列是一个通用的问题，广泛存在于通信、气象、金融、交通、销售等各行各业。由于时间序列分析与数字信号处理$(DSP,Digital\ Signal\ Processing)$有着很强的关联系，分析方法也有很多共同点。本文将主要针对预估，结合两者从时间序列的分解特性、预测原理、使用方法以及业界动态略作介绍。&lt;/p&gt;

&lt;p&gt;需要注意的是，时间序列分析通常看成是统计学家的工作。最常用的是$R$语言，其次是$Python$。如果能够掌握$R$语言，则拥有了大量的分析工具，可以快速验证分析方法以及预估策略的有效性。本文在结合品牌广告库存的分析基础上，参考相关博文、教材以及论文等，统一其变量等，梳理得到本文。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;主要内容&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;介绍时间序列分析的基础知识，如平稳性、相关性、周期性等；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;介绍线性时间序列分析的原理，如$AR、MA、ARMA、ARIMA$等；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;介绍非线性时间序列分析的原理，如$RNN、LSTM$等；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;介绍在时间序列分析在$Python$和$R$中的应用方法；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;介绍业界在时间序列分析方面的探索，如$Facebook$、$Google$等；&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;基础知识&lt;/h2&gt;
&lt;p&gt;### 时间序列分解
$Rob \ J\  Hyndman$在&lt;a href=&quot;https://www.otexts.org/fpp/6/1&quot;&gt;《Forecasting: principles and practice》&lt;/a&gt;指出，一个时间序列通常由4种成分构成：分别是趋势($Trend,T_t$)、季节变动($Seasonal,S_t$)、循环变动($Circular,C_t$)和不规则变动($Irregular,I_t$)。时间序列$Y_t$可以表示为以上4个因素的函数，即：
&lt;script type=&quot;math/tex&quot;&gt;X_t=f(T_t,S_t,C_t,I_t)  \tag{1}&lt;/script&gt;
时间序列分解的方法有很多，较常用的模型有加法模型和乘法模型。
加法模型为：
&lt;script type=&quot;math/tex&quot;&gt;X_t=T_t+S_t+C_t+I_t \tag{2}&lt;/script&gt;
乘法模型为：
&lt;script type=&quot;math/tex&quot;&gt;X_t=T_t\times S_t\times C_t\times I_t \tag{3}&lt;/script&gt;
加法模型如某品牌服饰在冬季的销量提升100万，乘法模型则如该服饰在冬季的销量增长$20\%$。一般而言，乘法模型可以通过取对数转化成加法模型；季节变动与循环变动存在差异；趋势可能会存在某个$change \ point$由增长转变为下降；去掉趋势和周期项之后的序列可能存在自回归特性。下面举一个简单的例子：
假设我们需要根据2017年7月1日之前的历史数据来预估未来4个月的库存情况，下图是2017年7月1日之前的历史库存(注：纵坐标为幅度，已经作了脱敏处理)：
&lt;img src=&quot;/img/history.png&quot; alt=&quot;某个维度历史库存&quot; /&gt;
结合上图的数据和一些时间序列的分析方法（后文将简要介绍），可以大致看出以下先验认识：
- 最近三年的该维度视频库存总量在稳步增长
- 在每年的除夕附近有大幅的下降（例如上图中2015年2月份的局部极小点实际为除夕当天）
- 在每年各个月份之间会有不同幅度的震荡（例如2016年8月份暑假明显高于2016年9月开学）
- 在每周中表现出一定的波动（例如图中的众多小“毛刺”点）
- 在暑假的波动幅度相对非暑假要小（例如2016年8月份暑假“毛刺”波动幅度比2016年9月份明显要小）&lt;/p&gt;

&lt;p&gt;如果希望通过传统的时间序列分析方法来预估未来，尤其是未来四个月的每日库存，则需要我们充分挖掘历史库存的信息量，这里我们以改进后的贝叶斯结构化模型$Prophet$为例来分析历史库存的重要构成成分。通过结合我们对库存数据的先验认识以及假设的似然函数，通过最大后验估计可以分解历史库存数据如下图：
分解历史数据得到下图：
&lt;img src=&quot;/img/with_summer_dpi_nofuture.png&quot; alt=&quot;时间序列分解&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到如下规律：
- 从trend趋势看，最近三年数据趋势稳步增长，在部分$change\ point$增长速率有变化；
- 从holiday节日看，每年除夕相对前后暴跌近30%，9月开学会下降，国庆节又会比较高；
- 从yearly周期来看，每年暑假（7月-8月）相对开学后（9月-10月）的波动高达20%左右；
- 从非暑假weekly周期看，每周六日的库存量相比工作日的波动在15%左右；
- 从暑假weekly周期看，每周六日的库存量相比工作日的波动在8%左右，比非暑假要小；&lt;/p&gt;

&lt;p&gt;如果能够把握住上面所提到五个重要构成的规律，我们可以进一步预估未来4个月的库存量，如下图：
&lt;img src=&quot;/img/compare.png&quot; alt=&quot;预估未来四个月库存&quot; /&gt;
上图中，横坐标表示时间，纵坐标表示取对数后并且归一化的某个维度库存数据，蓝色表示真实库存，绿色表示未来四个月的预估值，上图中未来120天的预估误差均值不超过8%，能有效克服把握住历史的长期增长趋势、全年季节的波动、暑假中的每周较小幅度波动以及非暑假每周较大幅度波动。可以看出，如果充分考虑到库存的季节变化规律，提取得到各个成分，将有利于降低库存预估误差，并且有助于用来预估更长时间跨度。&lt;/p&gt;

&lt;p&gt;然而，实际的业务数据存在各式各样的特点，例如历史数据不够长、波动性大、趋势由增长转下降、考察序列的粒度有分钟级或者秒级差异等，直接套用开源工具包不一定会取得良好的效果。此时需要回归到传统时间序列分析的道路上来，具体分析当前业务某个维度数据的平稳性、周期性、趋势、自回归特性等，可能需要分析时间序列的时间频率特性来验证直观的认识，也可能需要引入例如$LSTM$这样的模型来预估，本文将对这些基础性的工具和方法略作介绍。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;平稳性&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;引言：平稳性是时间序列分析的基础。然而实际数据大多是非平稳的，例如服务器在某个时段任务密集，负载存在波动性；从长期看，负载可能逐渐上升，体现出非平稳性。强平稳条件比较严苛，一般难以满足；一般通过时间序列的分解，去掉趋势和周期项，得到弱平稳序列，从而研究其自回归特性。平稳性的定义和划分可以参考《概率论与数理统计-盛骤》与《金融时间序列分析-蔡瑞胸》。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;强平稳
时间序列${r_t}$陈为严平稳的($Strictly\ Stationary$)，如果对所有的$t$，任意正整数$k$和任意$k$个正整数($t_1,t_2,…,t_k$),($r_{t_1},r_{t_2},…,r_{t_k}$)的联合分布与($r_{t_1+t},r_{t_2+t},…,r_{t_k+t}$)的联合分布是相同的。即严平稳性要求($r_{t_1},r_{t_2},…,r_{t_k}$)的联合分布在时间的平移变换下保持不变（注：要求联合分布保持不变，并非要求方差不变）。这是一个很强的条件。通常的时间序列并不满足，并且难以用经验方法验证。经常假定的是平稳性的一个较弱的形式。&lt;/li&gt;
  &lt;li&gt;弱平稳
如果$\forall l\in \mathcal{Z}$,$r_t$的均值以及$r_t$和$r_{t-l}$的协方差均不随时间而改变。即有满足如下两个条件：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
           \begin{array}{lr}  
           E(r_t)=\mu, \\
           Cov(r_t,r_{t-l})=r_l  &amp;
    \end{array}
    \tag{4}
\right.  
\end{equation} %]]&gt;&lt;/script&gt;
其中$\mu$是一个常数，$r_l$只依赖于$l$。
弱平稳性意味着数据的时间图显示出$T$个值在一个常数水平上下以相同的幅度波动。在应用中，弱平稳性使我们可以对未来观测进行推断，即预测。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-5&quot;&gt;相关性&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;引言：序列潜在的相关性是预测的前提，如果时间序列之间相互独立，则难以进行有效预估。在衡量相关性方面，主要有自相关和偏自相关。需要关注的是二者的区别，偏自相关衡量的是过去单项对当前的影响程度。偏自相关的定义可以参考《金融时间序列分析-蔡瑞胸》和《时间序列分析-汉密尔顿》。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;事件序列的自相关性一般可以用时间序列的如下三个统计量来体现：
- 自协方差函数($Autocovariance\ Function$)
- 自相关系数函数($Autocorrelation\ Coefficient\ Function,ACF$)
- 偏自相关系数函数($Partial\ Autocorrelation\ Coefficient\ Function,PACF$)&lt;/p&gt;

&lt;p&gt;具体如下：
- ACF
对于单个随机变量$X$，可以计算其均值$\mu$，方差$\sigma^2$；
对于两个随机变量$X和Y$，可以计算$X和Y$的协方差：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
     \begin{array}{lr}  
      cov(X,Y)=E[(X-\mu_X)(Y-\mu_Y)] &amp; \\
      \rho(X,Y)=\dfrac{cov(X,Y)}{\sigma_X\sigma_Y}
      \end{array}  
      \tag{5}
\right.  
\end{equation} %]]&gt;&lt;/script&gt;
他们衡量了两个不同事件之间的相互影响程度。
而对于时间序列${X_t,t \in T}$，任意时刻的序列值$X_t$都是一个随机变量，每一个随机变量都会有均值和方差，记$X_t$的均值为$\mu_t$和方差$\sigma_t$。则$\forall t,s \in T$，定义$X_t$的自协方差函数$\gamma(t,s)$和自协方差系数$\rho(t,s)$如下：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
     \begin{array}{lr}  
     \gamma(t,s)=E[(X_t-\mu_t)(X_s-\mu_s)] &amp; \\
    \rho(t,s)=\dfrac{cov(X_t,X_s)}{\sigma_t\sigma_s}
    \end{array}  
    \tag{6}
\right.  
\end{equation} %]]&gt;&lt;/script&gt;
$\gamma(t,s)$和$\rho(t,s)$衡量的是同一个事件在两个不同时期（时刻$t$和$s$）之间的相关程度，形象地讲就是衡量自己过去的行为对自己现在的影响。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PACF
假设$X_t$的一阶自相关系数$\rho_1 &amp;gt; 0$,则表明$X_t$与$X_{t-1}$相关，不过$X_{t-1}$又与$X_{t-2}$相关，$X_{t-3}$也会受到$X_{t-4}$的影响$…$。因此当我们计算$X_{t}$与$X_{t-1}$的自相关系数时，实际上我们既捕捉到了$t-1$项信息对$t$的影响，捕捉到了${t-2}$项信息对$t$的影响$…$。总而言之，$X_t$与$X_{t-1}$的自相关系数实际衡量的是包括过去数据对今天的影响总和。为了衡量过去单项对现在的影响效果，剔除其他项的作用，因此引入了偏自相关系数PACF。
假设$X_t$对$X_{t-1}、X_{t-2}、…X_{t-k}$的$k$阶线性回归方程：
&lt;script type=&quot;math/tex&quot;&gt;X_t=\phi_{k,1}X_{t-1}+\phi_{k,2}X_{t-2}+...+\phi_{k,k}X_{t-k}+\epsilon_{k,t}\ \tag{7}&lt;/script&gt;
其中所有参数$\phi_{k,j}(j=1,2,…,k)$的估计值应确保残差$\epsilon_{k,t}$的方差
&lt;script type=&quot;math/tex&quot;&gt;\delta_k=E[X_t-\sum_{j=1}^{k}\phi_{k,j}X_{t-j}]^2=\gamma_0-2\sum_{j=1}^k\phi_{k,j}\gamma_j+\sum_{i,j=1}^{k}\phi_{k,i}\phi_{k,j}\gamma_{i-j} \tag{8}&lt;/script&gt;
达到最小。
为此，类似于经典回归模型参数估计的最小二乘法，将$\delta_k$分别关于$\phi_{k,j}(j=1,2,…,k)$求偏导数，并令相应的结果为0，于是得到如下形式的线性方程组：
&lt;script type=&quot;math/tex&quot;&gt;\gamma_j=\sum_{i=1}^{k}\phi_{k,i}\gamma_{i-j},(j=1,2,...,k) \tag{9}&lt;/script&gt;
展开可以得到如下：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
   \begin{array}{lr}  
   \gamma_1=\phi_{k,1}\gamma_0+\phi_{k,2}\gamma_1+...+\phi_{k,k}\gamma_{k-1} &amp; \\
    \gamma_2=\phi_{k,1}\gamma1+\phi_{k,2}\gamma_0+...+\phi_{k,k}\gamma_{k-2} &amp; \\
    ... &amp; \\
     \gamma_k=\phi_{k,1}\gamma_{k-1}+\phi_{k,2}\gamma_{k-2} +...+\phi_{k,k}\gamma_0
 \end{array}  
 \tag{10}
\right.  
\end{equation} %]]&gt;&lt;/script&gt;
考虑到$\gamma_0=1$,上述方程可以进一步转化为：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{gather*}
\begin{bmatrix} r_1 \\ r_2 \\ . \\ .\\r_k \end{bmatrix}\quad=
\begin{bmatrix} 1 &amp; r_1 &amp;r_2 &amp; ... &amp; r_{k-1} \\1 &amp; r_1 &amp;r_2 &amp; ... &amp; r_{k-1} \\.  &amp; . &amp; . &amp; ... &amp; . \\.  &amp; . &amp; . &amp; ... &amp; . \\1 &amp; r_1 &amp;r_2 &amp; ... &amp; r_{k-1}    \end{bmatrix} \quad
\begin{bmatrix} \phi_1 \\ \phi_2 \\ . \\ . \\ \phi_k \end{bmatrix}\quad
\tag{11}
\end{gather*} %]]&gt;&lt;/script&gt;
上式称之为&lt;a href=&quot;http://www-stat.wharton.upenn.edu/~steele/Courses/956/ResourceDetails/YWSourceFiles/YW-Eshel.pdf&quot;&gt;$Yule-Walker$&lt;/a&gt;方程。从中可求解出$\phi_{k,1}、\phi_{k,2}、…、\phi_{k,k}$。其中的最后一个解$\phi_{k,k}$便为时间序列$X_t$延迟$k$阶偏自相关系数$PACF$。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-6&quot;&gt;周期性&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;引言：傅里叶分析在物理学、信号学、密码学、声学以及结构动力学等诸多领域都有着广泛的应用，上个世纪40年代以来，Fourier变换伴随着FFT(快速傅里叶变换)算法的快速发展而成为极其重要的数学工具。傅里叶变换可以用来挖掘时间序列的潜在周期模式，帮助提高预估准确性。下面，将按照傅里叶级数、傅里叶变换到离散傅里叶变换的顺序稍作介绍。傅里叶分析可以参考《数学物理方法-胡学刚》、《数学分析-陈传璋》、《信号与系统-郑君里》、《数字信号处理-程培青》以及《通信原理-周炯槃》。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;傅里叶级数
1822年，法国数学家傅里叶($J.Fourier,1768-1830$)在研究热传导理论时发表了“热点解析理论”，提出并证明了将周期函数展开为正弦级数的原理，奠定了傅里叶级数的理论基础。下面给出周期信号$\tilde{x}(t)$的傅里叶级数表达式：
&lt;script type=&quot;math/tex&quot;&gt;\tilde{x}(t)=\sum_{k=-\infty}^{+\infty} a_k e^{jkw_0t}\tag{12}&lt;/script&gt;
其中$j$为虚数单位，$w_0$为信号$\tilde{x}(t)$的基频，即为$w_0=\dfrac{2\pi}{T}$,$a_k$的计算如下式：
&lt;script type=&quot;math/tex&quot;&gt;a_k=\dfrac{1}{T}\int_{-T/2}^{T/2}\tilde{x}(t)e^{-jkw_0t}dt \tag{13}&lt;/script&gt;
周期的意义在于限定傅里叶系数的积分公式上下限,将$(13)$式带入到$(12)$中，两边恒等，其中利用了$e$指数的正交性。&lt;/li&gt;
  &lt;li&gt;连续傅里叶变换
然而这并不够，傅里叶级数只限定在周期信号，如果针对非周期信号$(12)$中的基频$w_0$将不存在（或者说无穷小，即$w_0\to0$），为了扩展应用范围，数学家们尝试定义非周期信号的傅里叶变换。区别在于非周期信号的基频$w_0\to0$，无穷小的求和可以用积分形式来表达。
假设上述周期信号$\tilde{x}(t)$就是根据$x(t)$扩展而得到，那么对于$\left| t  \right|\leq T/2$,有$x(t)$=$\tilde{x}(t)$。对于周期信号$\tilde{x}(t)$，对应的傅里叶系数为:
&lt;script type=&quot;math/tex&quot;&gt;a_k=\lim_{T\to \infty}\dfrac{1}{T}\int_{-T/2}^{T/2}\tilde{x}(t)e^{-jkw_0t}dt \\
=\lim_{T\to \infty}\dfrac{1}{T}\int_{-T/2}^{T/2}x(t)e^{-jkw_0t}dt \tag{14}\\
=\lim_{T\to \infty}\dfrac{1}{T}\int_{-\infty}^{+\infty}x(t)e^{-jkw_0t}dt&lt;/script&gt;
现在定义$X(jw)$为$Ta_k$的包络，其中的$kw_0$用$w$来代替，则得到如下：
&lt;script type=&quot;math/tex&quot;&gt;X(jw)=\int_{-\infty}^{+\infty}x(t)e^{-jwt}dt \tag{16}&lt;/script&gt;
显然，$a_k$只是$X(jw)$的等间隔采样：
&lt;script type=&quot;math/tex&quot;&gt;a_k=\dfrac{1}{T}X(jkw_0) \tag{17}&lt;/script&gt;
另外这里还可以注意到：
&lt;script type=&quot;math/tex&quot;&gt;\tilde{x}(t)=\sum_{k=-\infty}^{+\infty} a_k e^{jkw_0t} \tag{18} \\
=\sum_{k=-\infty}^{+\infty}\dfrac{1}{T}X(jkw_0)e^{jkw_0t} \\
=\sum_{k=-\infty}^{+\infty}\dfrac{1}{2\pi}X(jkw_0)e^{jkw_0t}w_0&lt;/script&gt;
观察上式，发现$\tilde{x}(t)$只由$w_0$与$kw_0$构成，即时域周期信号可以表示为离散的频域信号的组合。这表明傅里叶变换具有“时域周期则频域离散”的性质。&lt;/li&gt;
  &lt;li&gt;离散时间傅里叶变换DTFT
所谓离散时间，可以理解为”序列”。离散时间傅里叶变换也称为序列的傅里叶变换。其表达式如下：
&lt;script type=&quot;math/tex&quot;&gt;X(jw)=\sum_{n=-\infty}^{+\infty}x(n)e^{-jwn} \tag{19}&lt;/script&gt;
可以看出$X(j(w+2\pi M))=X(jw)$,即DTFT的频率是$w$的连续周期函数，周期为$2\pi$.
DTFT的时频特性可以总结为：时域离散，频率连续且以$2\pi$为周期。其中$0,2\pi,4\pi…$对应直流分量，$\pi,3\pi，5\pi…$对应信号的高频分量。
时域离散，频域周期。&lt;/li&gt;
  &lt;li&gt;离散傅里叶变换DFT
DFT在时域和频域都是离散的。可以看成是$Discrete\ time\ frequency \ Fourier\  Transform,DTFFT$的简称.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;X(k)=\sum_{n=0}^{n=N}x(n)W_N^{nk},k=0,1,...,N-1  \tag{20} \newline
\ &amp; x(n)=\dfrac{1}{N}\sum_{k=0}^{N-1}W_N^{-nk},n=0,1,...,N-1 \tag{21}
\end{align} %]]&gt;&lt;/script&gt;
 其中$W_N^{nk}=e^{-j\dfrac{2\pi}{N}nk}$.DFT的两个特性：时域和频域都是离散的；时域和频域点数都是有限的。可以方便在计算机中进行计算实现。且时域和频域均可在一个周期内完全反映出来。
$FFT$是$DFT$的一种高效算法，称为快速傅里叶变换($fast\space fourier\space transform$)。
傅里叶变换在时间序列分析中有重要的应用，下面举两个例子：&lt;/p&gt;

&lt;p&gt;（1）时间序列的多周期性
&lt;img src=&quot;/img/fft_long.jpg&quot; alt=&quot;时间序列的多周期性&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;时域特性分析：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上图为某个维度最近三年归一化库存数据，其中的黄色圆圈表示每年除夕的库存暴降，紫色圆圈代表的是每年暑假的库存上升以及开学后库存暴降的过程。整个库存展现出增长的趋势，年份之间还表现出一定的波动性。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;频域特性分析：
根据上述离散傅里叶DFT特性的分析，频率取值为：
$w_k=\dfrac{2\pi}{N}\tag{22}k$
或者：
$f_k=\dfrac{1}{N}k \tag{23}$
则对应得到信号的时域周期：
$n_k=\dfrac{1}{f_k}=\dfrac{N}{k} \tag{24}$
可以看到图中$T=365$、$T=7$以及$T=4$周期成分表现较为明显。
如果能够充分提取到库存序列的趋势、多周期特性则能有效提升预估性能。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;（2）时间序列的阶段周期性&lt;/p&gt;

&lt;p&gt;平时和暑假的周期特性表现有差异，暑假的周期中$T=7$表现不明显。
&lt;img src=&quot;/img/fft_period1.jpg&quot; alt=&quot;暑假和非暑假的week周期波动差异&quot; /&gt;
暑假的数据的周期成分低，波动性小；根据离散傅里叶变换的定义，用总共时间长度60除以横坐标，得到的是周期数，例如对红色线在17处，实际是60/17=3.5左右的周期&lt;/p&gt;

&lt;p&gt;（3）低通滤波器过滤异常点&lt;/p&gt;

&lt;p&gt;可以通过对时间序列的频谱进行低通滤波，过滤掉数据中异常存在的点。&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;模型识别&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;引言：经典的时间序列分析方法，通常采用自回归滑动平均的方法来建模，需要选择最优的参数值，然后预测模型。通常有两种方法：1.采用前述的相关函数法，通过相关函数的变化来推测模型参数的取值；2.定义模型的选择指标，兼顾模型的表达能力与简单性。可以参考《金融时间序列分析-蔡瑞胸》。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;section-8&quot;&gt;相关函数法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;ACF&lt;/li&gt;
  &lt;li&gt;PACF
#### 信息准则法
$AIC$是一种用于模型选择的指标，同时考虑了模型的拟合程度以及简单性，而$BIC$则是对$AIC$的一个改进，具体的定义如下：&lt;/li&gt;
  &lt;li&gt;AIC准则
$Akaike$信息准则($AIC$)定义如下：
&lt;script type=&quot;math/tex&quot;&gt;AIC=\dfrac{-2}{T}ln(似然函数的最大值)+\dfrac{l\cdot 2}{T}\tag{25}&lt;/script&gt;
其中$T$是样本容量,$l$是参数的个数。第一项度量的是模型对数据的拟合优度，而第二项称为准则中的惩罚函数。参数个数越多，第二项的惩罚越大。&lt;/li&gt;
  &lt;li&gt;BIC准则
$Schwarz$贝叶斯信息准则($BIC$)定义如下：
&lt;script type=&quot;math/tex&quot;&gt;BIC=ln(\widetilde{\sigma}_l^2)+\dfrac{l\cdot ln(T)}{T}\tag{26}&lt;/script&gt;
在$AIC$准则中对每个参数的惩罚为2，而在$BIC$中为$ln(T)$，当样本容量适度或较大时，$BIC$会更倾向于一个低阶的模型。
一般而言，较小的$AIC$或者$BIC$表明模型在保持简单的同时能够很好地对时间序列进行拟合。因此，我们往往会选择具有最小的$AIC$或者$BIC$的模型作为相对最优的模型。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-9&quot;&gt;模型检验&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;引言：时间序列的平稳性是许多时间序列分析方法的前提，在构建模型用来预测未来之前，需要检验该时间序列的平稳性。检验方法一般有三种：观察时序图、观察相关函数图以及单位根检验法。另外，应用模型提取时间序列的趋势、周期、自回归等特性后，还需要检测残差序列是否为白噪声，如果不是白噪声，从信息论角度看，模型还没有完全表达序列数据，即为欠拟合。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;section-10&quot;&gt;平稳性检验&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;时序图观察法
根据弱平稳的定义，序列的均值和方差是一个常数。也就是说平稳时间序列的序列值在一个常数水平上下波动，并且波动幅度接近。因此，如果序列数据围绕一个水平线上下以大致相同的幅度波动，那么该时间序列可能具备弱平稳性。&lt;/li&gt;
  &lt;li&gt;相关函数观察法
一般对平稳时间序列而言，其自相关函数或者偏自相关函数大都可以快速减小到0或者在某一个阶段之后变为0,而非平稳序列一般不具备这样的性质。&lt;/li&gt;
  &lt;li&gt;单位根检验
上述两种方法都是通过观察的方法来完成，存在一定的主观性。单位根检验可以比较客观判断序列的平稳特性。如果时间序列是非平稳的，可以通过$d$次差分($Difference$)可以将其转化为平稳序列，称差分得到的序列为$I(d)$，其中$I$意指整合($Integrated$),$d$为整合阶数，例如：
&lt;script type=&quot;math/tex&quot;&gt;x_t=x_{t-1}+\epsilon_t\tag{27}&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中$x_0=0$,$\epsilon_t \sim N(0,\sigma^2&lt;em&gt;{\epsilon})$,则可以得到：
&lt;script type=&quot;math/tex&quot;&gt;E(x_t)=0 \tag{28}&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;Var(x_t)=Var(x_{t-1})+\sigma^2_\epsilon=...=t\sigma^2_\epsilon\tag{29}&lt;/script&gt;
因为$x_t$的方差会随着时间而改变，因此该时间序列是非平稳的。然而$x_t$经过一阶差分之后将为平稳的时间序列，因此$x_t$为非平稳的$I(1)$序列。一个时间序列是否平稳可以借助于滞后算子($Lag\ Operator$)多项式方程的根来表述。滞后算子是将一个时间序列的前一个值转化为当前值，通常用$L$表示，即$Lx_t=x&lt;/em&gt;{t-1}$,也有的领域文献或者以$B$来表示，取自$BackShift$,同样表示后移算子的意思。在信号与系统中，也常引入$L$来分析系统的稳定性。那么上式可以改写为：
&lt;script type=&quot;math/tex&quot;&gt;(1-L)x_t=\epsilon_t\tag{30}&lt;/script&gt;
其中$1-L=0$称为滞后算子多项式，得到根$L=1$。因此$x_t$称为单位根过程。时间序列${x_t}$是随机游走过程，其滞后算子多项式的根有单位根，是个非平稳的时间序列。如果序列非平稳，则预估难以进行，通常采用$DF(Dickey-Fuller\ Test)$检验或者$ADF(Augmented Dickey-Fuller\ Test)$检验来确认序列是否存在单位根。
假设一个简单的$AR(1)$模型是$y_t=\rho y_{t-1}+\epsilon_t$,如果$\left |\rho \right | \geq 1$，则说明单位根是存在的。回归模型可以进一步写成：
&lt;script type=&quot;math/tex&quot;&gt;\Delta y_t=(\rho-1)y_{t-1}+\epsilon_t\tag{31}&lt;/script&gt;
其中$\Delta$是一阶差分。测试是否存在单位根等同于测试否$\rho=1$.$ADF$检验与$DF$检验类似，但ADF检验的好处在于它排除了自相关的影响。$ADF$检验的模型为：
&lt;script type=&quot;math/tex&quot;&gt;\Delta y_t=\alpha+\beta t+\gamma y_{t-1}+\delta_1\Delta y_{t-1}+...++\delta_p\Delta y_{t-p}+\epsilon_t\tag{32}&lt;/script&gt;
其中$\alpha$为对应截距，$\beta$为对应趋势。针对ADF的假设检验为：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
     \begin{array}{lr}  
    H_0：\gamma=0 &amp;\\
    H_1：\gamma=1
   \end{array}  
   \tag{32}
\right.  
\end{equation} %]]&gt;&lt;/script&gt;
该检验对应的统计量为：
&lt;script type=&quot;math/tex&quot;&gt;DF=\dfrac{\hat \gamma}{SE(\gamma )}\tag{33}&lt;/script&gt;
如果该统计量比临界值小，则拒绝原假设，也就是认为序列是平稳的，否则认为序列是非平稳的。&lt;/p&gt;

&lt;h4 id=&quot;section-11&quot;&gt;白噪声检验&lt;/h4&gt;
&lt;p&gt;时间序列${r_t}$称为一个白噪声序列，如果${r_t}$是一个具有有限均值和有限方差的独立同分布随机变量序列。特别地，若${r_t}$还服从均值为0、方差为$\sigma^2$的正态分布，则称这个序列为高斯白噪声。对白噪声序列，所有自相关函数为0。在实际应用中，如果所有样本自相关函数接近于0，则认为该序列是白噪声序列。
白噪声是一种理想存在；信息熵最大，完全未知的情况；
白噪声检验也成为纯随机性检验，一般是构造检验统计量来检验序列的纯随机性，常见的检验统计量有$Q$统计量、$LB$统计量由样本各延迟期数的自相关系数可以计算得到检验统计量，然后计算得到对应的$p$值
，如果$p$值显著大于显著性水平$alpha$，则表示该序列不能拒绝纯随机的原假设，该序列已经没有什么可以挖掘的有用信息，因而可以停止对该序列的分析。
通常我们用$Ljung-Box$检验，简称$LB$检验。简单来说$LB$检验的原假设为所检验序列为纯随机序列(白噪声过程),该检验的统计量为$Q$统计量：
&lt;script type=&quot;math/tex&quot;&gt;Q(m)=n(n+2)\sum_{1}^m\dfrac{\rho_k^2}{n-k}\sim\chi_m^2\tag{34}&lt;/script&gt;
其中，$\rho_k^2$是序列的$k$阶自相关系数，$n$是整个序列中观测值的个数，$m$是设定的滞后阶数。
根据$Q(m)$公式可知，$Q(m)$均为正数并且与数值大小与序列的自相关系数呈正相关。即当序列有自相关时，其自相关系数较大、对应的$Q(m)$也较大；反之，当序列为随机序列、无自相关性时，序列的自相关系数不会显著地异于0，$Q(m)$也会很小。
检验一个时间序列在$m$阶内是否是白噪声，只有当$Q(1),Q(2),…,Q(m)$这$m$个统计量都小于对应的$\chi^2$分布的临界值，才能说明该序列在所检验的$m$阶内是纯随机的。
&amp;gt;$LB$检验在$R$中可以调用$Box.test()函数来实现。$&lt;/p&gt;

&lt;h3 id=&quot;section-12&quot;&gt;参数估计&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;引言：通过分析数据特性，然后假设序列服从某种先验的规律之后，例如指定逻辑回归形式的增长函数，接下来需要进一步确定模型的参数。通常由两种典型的方法：最大似然法和最大后验法。分别属于频率学派和贝叶斯学派。对于参数估计的理论可以参考《Pattern Recognition and Machine Learning- Christopher Bishop 》以及《The Elements of Statistical Learning-Trevor Hastie》。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;最大似然法$MLE$与最大后验法$MAP$来估计模型的参数，确定模型的$p,q$等。
在上一篇文章《攻略推荐流程简介》中已经对$MLE$与$MAP$在应用逻辑回归来预测广告点击率中略作介绍，这里进一步对这两者进行统一。
先验分布：$p(\theta)$
似然函数:   $p(D|\theta)$
后验分布：$p(\theta|D)$
其中$\theta$为参数，$D$为数据集。他们之间的关系：
&lt;script type=&quot;math/tex&quot;&gt;p(\theta|D)=\dfrac{p(\theta)\cdot p(D|\theta)}{p(D)}\tag{35}&lt;/script&gt;
#### 最大似然估计
最大后验估计就是指假设数据符合某个模型，但参数未知，然而当前$D$已经为既定事实，则希望寻求参数$\theta$使“似然”当前事实的可能性最大。即如下：
&lt;script type=&quot;math/tex&quot;&gt;\theta_{MLE}=arg \underset{\theta}{max}\ p(D|\theta) \tag{36} \\
\hspace {19mm}=arg \underset{\theta}{max}\ \underset{i=1}{\Pi}p(D_i|\theta)  \\
\hspace {21mm}=arg \underset{\theta}{max}\ \sum_{i=1}ln p(D_i|\theta)  \\&lt;/script&gt;
#### 最大后验估计
最大后验是指最大化$p(\theta|D)$, 意指在当前$D$情况下，结合参数$\theta$的先验分布和似然函数$p(D|\theta)$，估计参数$\theta$，
&lt;script type=&quot;math/tex&quot;&gt;\theta_{MAP}=arg \underset{\theta}{max}\ p(\theta|D) \tag{37}  \\
\hspace {19mm}=arg \underset{\theta}{max}\ p(\theta)\cdotp(D|\theta)  \\
\hspace {30mm}=arg \underset{\theta}{max}\ \underset{i=1}{\Pi}p(D_i|\theta) \cdot p(\theta)  \\
\hspace {44mm}=arg \underset{\theta}{max}\ \sum_{i=1}lnp(D_i|\theta)+ lnp(\theta) \\&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;mapmle&quot;&gt;MAP与MLE相统一&lt;/h4&gt;
&lt;p&gt;如果假设先验一无所知，$p(\theta)$为均匀分布，则$lnp(\theta)$为常数，此时二者等价。&lt;/p&gt;

&lt;h2 id=&quot;section-13&quot;&gt;线性时间序列分析&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;引言：一般教材对时间序列的分析方法划分标准是：是否平稳。这里划分的标准是：是否线性。主要原因有两个：1.实际业务数据大部分是非平稳的，潜在包含增长性、周期性等；2.伴随深度学习日趋火热，RNN、LSTM等递归性甚至CNN在时间序列预估方面也有尝试。因此，我们我们将分析方法划分为线性和非线性。在前者中，我们简要介绍传统的时序分析经典方法ARIMA，在后者中，我们简要介绍LSTM的理论。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;ar&quot;&gt;自回归模型AR&lt;/h3&gt;
&lt;p&gt;$AR$模型是以以前$p$期序列值$x_{t-1},x_{t-2},…,x_{t-p}$为自变量，随机变量$X_t$的取值$x_t$为因变量建立得到的线性回归模型。
&lt;script type=&quot;math/tex&quot;&gt;\forall t,x_t=a_0+\sum_{i=1}^pa_ix_{t-i}+ \epsilon_t     \tag{38}&lt;/script&gt;
- 其中，$\epsilon_ts$ 是均值为0，标准差为$\sigma$的随机变量；
- $a_1,…,a_p$为自回归系数；
- $x_t$为观察的随机变量。&lt;/p&gt;

&lt;p&gt;对满足平稳性条件的$AR(p)$模型的方程，两边取期望，得：
&lt;script type=&quot;math/tex&quot;&gt;E(x_t)=E(a_0+a_1x_{t-1}+a_2x_{t-2}+...+a_px_{t-p}+ \epsilon_t )\tag{39}&lt;/script&gt;
已知$E(x_t)=\mu,E(\epsilon_t)=0$，因此：
&lt;script type=&quot;math/tex&quot;&gt;u=a_0+a_1u+a_2u+...+ a_pu&lt;/script&gt;
从而得到：
&lt;script type=&quot;math/tex&quot;&gt;\mu=\dfrac{a_0}{1-a_1-a_2-...-a_p}\tag{40}&lt;/script&gt;
- 均值
若$1-a_1-a_2-…-a_p \neq 0$，则$x_t$的均值存在。$x_t$的均值为0，当且仅当$a_0=0$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;方差
平稳$AR(p)$模型的方差有界，等于常数。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$ACF$
平稳$AR(p)$模型的自相关系数$\rho_k$呈指数速度衰减，始终有非零值，不会再$k$大于某个常数滞后就恒等于0，表明$\rho_k$具有拖尾性&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$PACF$
平稳$AR(p)$模型的偏自相关系数具有截尾性。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$AR(p)$模型的自相关系数具有拖尾性以及偏自相关系数具有截尾性是模型识别的重要依据。&lt;/p&gt;

&lt;h3 id=&quot;ma&quot;&gt;滑动平均模型MA&lt;/h3&gt;

&lt;p&gt;$MA$模型是指随机变量$X_t$的取值$x_t$与以前各期的序列值无关，建立$x_t$与前$q$期的随机扰动$\epsilon_{t-1}, \epsilon_{t-2},…,\epsilon_{t-q}$得到的线性回归模型。
&lt;script type=&quot;math/tex&quot;&gt;\forall t,x_t=\sum_{j=1}^qb_j\epsilon_{t-j}+ \epsilon_t     \tag{41}&lt;/script&gt;
- 其中，$b_1,…,b_q$为移动平滑系数。
- $E(\epsilon_t)=0;Var(\epsilon_t)=\sigma^2_\epsilon;E(\epsilon_t\epsilon_s)=0,\forall s\neq$t
由于$MA(q)$仅有白噪声过程线性组合，因此有：
&lt;script type=&quot;math/tex&quot;&gt;E(x_t)=\mu&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;Var(x_t)=r_0=(1+\theta^2_1+\theta^2_2+...+\theta^2_q)\sigma^2_\epsilon&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\rho_l=
\left\{  
     \begin{array}{lr}  
    1,\hspace {67mm} l=0&amp; \\
   \dfrac{\theta_l+\theta_{l+1}\theta_1+\theta_{l+2}\theta_2+...+\theta_{q}\theta_{q-l}}{(1+\theta^2_1+\theta^2_2+...+\theta^2_q)},\forall l=1,2,...q $\\
   0,\hspace {67mm} l=0 \forall l&gt;q
    \end{array}  
\right.  
\tag{42}
\end{equation} %]]&gt;&lt;/script&gt;
这表明$MA(q)$具有以下性质：
-$ACF$
自相关系数q阶截尾,即$q$阶以后的$MA(q)$模型的自相关系数马上截止，$q+1$阶就等于0。
-$PACF$
几何型或者振荡型。&lt;/p&gt;

&lt;h3 id=&quot;arma&quot;&gt;自回归滑动平均模型ARMA&lt;/h3&gt;

&lt;p&gt;随机变量$X_t$的取值$x_t$不仅与以前$p$期的序列值有关，还与前$q$期的随机扰动有关。
&lt;script type=&quot;math/tex&quot;&gt;\forall t,x_t=\sum_{i=1}^p\phi_ix_{t-i}+\sum_{j=1}^q\theta_j\epsilon_{t-j}+ \epsilon_t     \tag{43}&lt;/script&gt;
很显然，相对于$AR(p)$和$MA(q)$模型，$ARMA(p,q)$模型更具有普适性。并且$AR(p)$是$q=0$的$ARMA(p,q)$模型，$MA(q)$是$p=0$的$ARMA(p,q)$模型&lt;/p&gt;

&lt;p&gt;在模型识别与估计中，需要决定$p$和$q$的值，选出相对最优的模型结构。通过时间序列的自相关函数$ACF$以及$PACF$大致决定。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;模型&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$ACF$&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$PACF$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$AR(p)$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;拖尾（几何型或者振荡型）&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$p$阶截尾&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$MA(q)$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$q$阶截尾&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;拖尾（几何型或者振荡型）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ARMA(p,q)$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;拖尾（几何型或者振荡型）&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;拖尾（几何型或者振荡型）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;如果通过观察序列的$ACF$和$PACF$来判断$p$和$q$的值不是很明确，可以尝试建立多个模型，然后通过$AIC$或则$BIC$指标来选择。&lt;/p&gt;

&lt;h3 id=&quot;arima&quot;&gt;单位根非平稳性与ARIMA&lt;/h3&gt;

&lt;p&gt;许多非平稳序列差分后会显示出平稳序列的性质，称这个非平稳序列为差分平稳序列。对差分平稳序列可以使用$ARIMA$模型进行拟合。
非平稳时间序列经过差分之后得到平稳的时间序列，然后通过上述的$ARMA$来建模，假设$x_t^{\prime}$是差分$d$次得到的平稳序列，其表达式如下：
&lt;script type=&quot;math/tex&quot;&gt;\forall t,x_t^{\prime}=\sum_{i=1}^p\phi_ix_{t-i}^{\prime}+\sum_{j=1}^q\theta_j\epsilon_{t-j}+ \epsilon_t     \tag{44}&lt;/script&gt;
一般称该模型为$ARIMA(p,d,q)$，其中：
$p$=自回归的阶数
$d$=差分的阶数
$q$=滑动平滑的阶数
结合之前的滞后算子，则上述表达式如下：
&lt;script type=&quot;math/tex&quot;&gt;(1-\phi_1L-...-\phi_pL^p)\   (1-L)^d \ x_t=\mu+(1+\theta L+...+\theta_q L^q)\epsilon_t \tag{45}&lt;/script&gt;
其中$(1-\phi_1L-…-\phi_pL^p)$表示序列的$p$阶自回归$AR(p)$特性，(1-L)^d表示序列的$d$阶差分平稳$I(d)$特性，$(1+\theta L+…+\theta_q L^q)$表示序列的$q$阶滑动平均$MA(q)$特性.&lt;/p&gt;

&lt;h3 id=&quot;sarima&quot;&gt;季节模型与SARIMA&lt;/h3&gt;

&lt;p&gt;全称为$Seasonal\  Auto \ Regressive\  Integrated\  Moving\  Average$，季节性差分自回归滑动平均模型。运用$ARMA$模型的前提条件是时间序列为零均值的平稳随机过程。对于包含趋势性或季节性的非平稳时间序列，须经过适当的逐期差分及季节差分消除趋势影响后，在对形成的新的平稳序列建立$ARMA(p,q)$模型进行分析。对于只包含趋势性的原序列，可以表示为$ARIMA(p,d,q)$模型；若原序列同时包含季节性和趋势性，则可以表示为$ARIMA(p,d,q)(P,D,Q)_s$模型，其中的$d,D$分别为逐期差分和季节差分的阶数，$p,q$分别为自回归和滑动平均的阶数，$P,Q$分别为季节自回归和季节移动平均的阶数。&lt;/p&gt;

&lt;h2 id=&quot;section-14&quot;&gt;非线性时间序列分析&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;引言：近些年来，深度学习除了在文本、语音、图像上面有很大的突破。以RNN、LSTM为代表的循环神经网络被引入自然语言处理以及时间序列分析，关于LSTM及其演化可以参考&lt;a href=&quot;http://www.bioinf.jku.at/publications/older/2604.pdf&quot;&gt;《Long short-term memory》&lt;/a&gt;、&lt;a href=&quot;http://zacklipton.com/media/papers/recurrent-network-review-lipton-2015v2.pdf&quot;&gt;《A Critical Review of Recurrent Neural Networks for Sequence Learning》&lt;/a&gt;以及&lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs&quot;&gt;《Understanding LSTM by Colah》&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;lstm&quot;&gt;LSTM&lt;/h3&gt;
&lt;p&gt;LSTM的经典网络结构图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/lstm.jpg&quot; alt=&quot;LSTM网络结构图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中涉及三个门，分别如下：&lt;/p&gt;

&lt;p&gt;forget gate:
&lt;script type=&quot;math/tex&quot;&gt;f_t=\sigma(W_f\cdot[h_{t-1},x_t])+b_f \tag{46}&lt;/script&gt;
input gate:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
     \begin{array}{lr}  
    i_t= \sigma(W_i\cdot[h_{t-1},x_t]+b_i) &amp; \\
    \tilde{C_t}=tanh(W_C\cdot[h_{t-1},x_t]+b_C)
    \end{array}  
\right.  
\tag{47}
\end{equation} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;output:
&lt;script type=&quot;math/tex&quot;&gt;C_t=f_t*C_{t-1}+i_t*\tilde{C_t} \tag{48}&lt;/script&gt;
若令$x_c{t}=[x_t,h_{t-1}]$，则有如下前向网络：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
     \begin{array}{lr}  
    f_t= \sigma(W_f\cdot [x_t ,h_{t-1}]+b_o) &amp; \\
    i_t= \sigma(W_i\cdot [x_t ,h_{t-1}]+b_o) &amp; \\
    g_t= tanh(W_g\cdot [x_t ,h_{t-1}]+b_o) &amp; \\
    o_t= \sigma(W_o\cdot [x_t ,h_{t-1}]+b_o) &amp; \\
    s_t= s_{t-1} \cdot f_t+ i_t \cdot g_t &amp; \\
    h_t=o_t*tanh(s_t)
    \end{array}  
\right.  
\tag{49}
\end{equation} %]]&gt;&lt;/script&gt;
目标函数为：
&lt;script type=&quot;math/tex&quot;&gt;l(t)=\dfrac{1}{2}(h_t-y_t)^2 \tag{50}&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;L=\sum_{t=1}^{T}l(t)=\dfrac{1}{2}\sum_{t=1}^{T}(h_t-y_t)^2 \tag{51}&lt;/script&gt;
另外激活函数
&lt;script type=&quot;math/tex&quot;&gt;\begin{equation}  
\left\{  
     \begin{array}{lr}  
    \sigma(x)= \dfrac{1}{1+e^{-x}} \\
    tanh(x)=\dfrac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
    \end{array}  
\right.  
\tag{52}
\end{equation}&lt;/script&gt;
其对应的导数是：
&lt;script type=&quot;math/tex&quot;&gt;\begin{equation}  
\left\{  
     \begin{array}{lr}  
    \sigma&#39;(x)= x \cdot (1-x) \\
    tanh&#39;(x)= 1-tanh^2(x)
    \end{array}  
\right.  
\tag{53}
\end{equation}&lt;/script&gt;
关于LSTM的文献汗牛充栋，然而各个文献的变量标记大都各有差异，在前向传播和反向梯度计算的理论以及实现细节上面都鲜有完整，为了更好理解LSTM的前向网络传播以及反向梯度计算，展开其结构，并以电路图结构展示如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/LSTM电路图.jpg&quot; alt=&quot;LSTM电路图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图，在前向网络传播时，输入为当前时刻的输入$x_t$以及上一个时刻的输出$h_{t-1}$构成，令：&lt;script type=&quot;math/tex&quot;&gt;x_c(t)=[x_t,h_{t-1}] \tag{54}&lt;/script&gt;
其中$c$表示$concat$连接之意。
图中黄色区域中可以理解为通过1个全连接层，然后级联4个激活函数，从而得到$f_t、a_t、i_t、o_t$,表达式如下：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
     \begin{array}{lr}  
    f(t)= \sigma(W_{fx}x_t +W_{fh}h_{t-1}+b_f) &amp; \\
    a(t)= \tanh(W_{ax}x_t +W_{ah}h_{t-1}+b_a) &amp; \\
    i(t)= \sigma(W_{ix}x_t +W_{ih}h_{t-1}+b_i) &amp; \\
    o(t)= \sigma(W_{ox}x_t +W_{oh}h_{t-1}+b_o) &amp; \\
    s_t= s_{t-1} \cdot f_t+ i_t \cdot a_t &amp; \\
    h_t=o_t*tanh(s_t)
    \end{array}  
\right.  
\tag{55}
\end{equation} %]]&gt;&lt;/script&gt;
可以图示理解如下：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{gather*}
\begin{bmatrix} x \\ h \end{bmatrix}\quad
\rightarrow
\begin{bmatrix} W_{fx} &amp; W_{fh} \\ W_{ax} &amp; W_{ah} \\ W_{ix} &amp; W_{ih} \\ W_{ox} &amp; W_{oh} \\  \end{bmatrix} \quad
\begin{bmatrix} x \\ h \end{bmatrix}\quad
+
\begin{bmatrix} b_f \\ b_a\\b_i\\b_o \end{bmatrix}\quad
\rightarrow
\begin{bmatrix} \sigma \\ \phi\\ \sigma\\\sigma \end{bmatrix}\quad
\rightarrow
\begin{bmatrix} f(t) \\ a(t)\\ i(t)\\o(t)\end{bmatrix}\quad
\end{gather*} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;记：
&lt;script type=&quot;math/tex&quot;&gt;\begin{gather*}
W_x=\begin{bmatrix}W_{fx} \\W_{fax}\\ W_{ix}\\W_{ox}\end{bmatrix},\quad
W_h=\begin{bmatrix}W_{fh} \\W_{fah}\\ W_{ih}\\W_{oh}\end{bmatrix},\quad
gates_t=\begin{bmatrix} f(t) \\ a(t)\\ i(t)\\o(t)\end{bmatrix}\quad
\end{gather*}&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;bptt&quot;&gt;BPTT反向传播算法&lt;/h3&gt;
&lt;p&gt;根据链式求导法则，因此可以得到反向传播的梯度BPTT算法，得到针对$h_t$的导数如下：
&lt;script type=&quot;math/tex&quot;&gt;\dfrac{d_{L(t)}}{d_{h(t)}} = \dfrac{d_{l(t)}}{d_{h(t)}} +\dfrac{d_{L(t+1)}}{d_{h(t)}}\tag{56}&lt;/script&gt;
其中第一项比较简单：
&lt;script type=&quot;math/tex&quot;&gt;\dfrac{d_{l(t)}}{d_{h(t)}}=h(t)-y(t) \tag{57}&lt;/script&gt;
第二项的计算为：
&lt;script type=&quot;math/tex&quot;&gt;\dfrac{d_{L(t+1)}}{d_{h(t)}}=W_h^T\delta gates_t \tag{58}&lt;/script&gt;
其中：
&lt;script type=&quot;math/tex&quot;&gt;\begin{gather*}
\delta gates_t=\begin{bmatrix} f&#39;(t) \\ a&#39;(t)\\ i&#39;(t)\\o&#39;(t)\end{bmatrix}\quad
\tag{59}
\end{gather*}&lt;/script&gt;
另外对$s(t)$的依赖关系如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/LSTM级联.jpg&quot; alt=&quot;依赖关系图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;则其导数为：&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left .   
     \begin{array}{lr}  
     \dfrac{d_{L(t)}}{d_{s(t)}} = \dfrac{d_{l(t)}}{d_{s(t)}} +\dfrac{d_{L(t+1)}}{d_{s(t)}}&amp;\\
                 \hspace {12mm}= \dfrac{d_{l(t)}}{d_{s(t)}} +\dfrac{d_{L(t+1)}}{d_{s(t)}}&amp;\\
			    \hspace {12mm}= \dfrac{d_{l(t)}}{d_{h(t)}} \cdot  \dfrac{d_{h(t)}}{d_{s(t)}}+\dfrac{d_{L(t+1)}}{d_{s(t+1)}} \cdot \dfrac{d_{s(t+1)}}{d_{s(t)}}  &amp;\\
			    \hspace {12mm}= \dfrac{d_{l(t)}}{d_{h(t)}} \cdot o_t \cdot (1-tanh^2(s_t))+\dfrac{d_{L(t+1)}}{d_{s(t+1)}} \cdot f_t
    \end{array}  
\right.  
\tag{60}
\end{equation} %]]&gt;&lt;/script&gt;
上式也可以看出$\dfrac{d_{L(t)}}{d_{s(t)}}$具有递归特性。
当得到$h_t、s_t$的导数递归表达形式之后，其他的$f_t、a_t、i_t、o_t$的梯度表达式易得，整体如下：
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{equation}  
\left\{  
     \begin{array}{lr}  
   \dfrac{d_{L(t)}}{d_{h(t)}} = \dfrac{d_{l(t)}}{d_{h(t)}} +\dfrac{d_{L(t+1)}}{d_{h(t)}} &amp;\\
   \hspace {12mm}=\dfrac{d_{l(t)}}{d_{h(t)}} +W_h^T\delta gates_t &amp;\\
   \dfrac{d_{L(t)}}{d_{s(t)}} = \dfrac{d_{l(t)}}{d_{s(t)}} +\dfrac{d_{L(t+1)}}{d_{s(t)}} &amp;\\
   \hspace {12mm} = \dfrac{d_{l(t)}}{d_{h(t)}} \cdot o_t \cdot (1-tanh^2(s_t))+\dfrac{d_{L(t+1)}}{d_{s(t+1)}} \cdot f_t &amp;\\
   \dfrac{d_{L(t)}}{d_{f(t)}}=\dfrac{d_{L(t)}}{d_{s(t)}} \cdot \dfrac{d_{s(t)}}{d_{f(t)}} &amp;\\
     \hspace {12mm} =\dfrac{d_{L(t)}}{d_{s(t)}} \cdot s_{t-1} \cdot f_t \cdot(1-f_t) &amp;\\
\dfrac{d_{L(t)}}{d_{a(t)}}=\dfrac{d_{L(t)}}{d_{s(t)}} \cdot \dfrac{d_{s(t)}}{d_{a(t)}} &amp;\\
     \hspace {12mm} =\dfrac{d_{L(t)}}{d_{s(t)}} \cdot i_t \cdot(1-a^2_t) &amp;\\
 \dfrac{d_{L(t)}}{d_{i(t)}}=\dfrac{d_{L(t)}}{d_{s(t)}} \cdot \dfrac{d_{s(t)}}{d_{i(t)}} &amp;\\
     \hspace {12mm} =\dfrac{d_{L(t)}}{d_{s(t)}} \cdot a_t \cdot i_t \cdot(1-i_t) &amp;\\
      \dfrac{d_{L(t)}}{d_{o(t)}}=\dfrac{d_{L(t)}}{d_{h(t)}} \cdot \dfrac{d_{h(t)}}{d_{o(t)}} &amp;\\
     \hspace {12mm} =\dfrac{d_{L(t)}}{d_{h(t)}} \cdot tanh(s_{t}) \cdot a_t \cdot o_t \cdot(1-o_t) &amp;\\
    \end{array}  
\right.  
\tag{61}
\end{equation} %]]&gt;&lt;/script&gt;
除了在线性模型中介绍的通过分解来预测，我们也在探索应用LSTM以及CNN的方法来做时间序列分析，后续文章也将逐渐展开非线性方法的应用效果。
## 业界方案
&amp;gt;针对非平稳时间序列的分析，业界已经开源了不少工具，主要是R语言算法包，例如STL、Forecast、Prophet、bsts等，下面简要介绍其中Forecast和Prophet。&lt;/p&gt;

&lt;h3 id=&quot;forecast&quot;&gt;Forecast&lt;/h3&gt;
&lt;p&gt;提到时间序列分析，不得不提STL和Forecast，这是在R语言中很易用的功能，为一些数学家和统计学家所钟爱。下面稍微介绍下：
- LOWESS
局部加权回归，全称为$LOcally\  wEight\ Scatterplot \ Smoothing(LOESS)$,利用低次多项式来拟合在数据集上的每个点，距离越近的点，权重就越高，相反距离越远，权重就越低。
- STL
全称为$Seasonal-Trend\ decomposition\ procedure \ based \ on \ Loess$,通过内外两层循环将时间序列分解为趋势项、季节项以及残余项。STL的流程如下：
&lt;code class=&quot;highlighter-rouge&quot;&gt;cpp
outer loop：
	计算robustness weight；
	inner loop：
		Step 1 :去趋势；
		Step 2: 周期子序列平滑；
		Step 3: 周期子序列的低通量滤波；
		Step 4: 去除平滑周期子序列趋势；
		Step 5: 去周期；
		Step 6: 趋势平滑；
&lt;/code&gt;
为了使得算法具有足够的鲁棒性，所以设计了内循环和外循环。如果时间序列中有异常点，则余项会比较大。假设数据点$v$的余项为$R_v$,则定义：
&lt;script type=&quot;math/tex&quot;&gt;h=6*median(|R_v|)  \tag{62}&lt;/script&gt;
该点的$Robustness \ Weight$为:
&lt;script type=&quot;math/tex&quot;&gt;\rho_v=B(|R_v|/h) \tag{63}&lt;/script&gt;
 其中$B$函数为$bisquare$函数：
 &lt;script type=&quot;math/tex&quot;&gt;B(u)=
 \begin{equation}  
\left\{  
     \begin{array}{lr}  
   (1-u^2)^2 \ \ for \ u\in[0,1)\\
   0 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ for\ u\in[1,+\infty)
    \end{array}  
\right.  
\tag{64}
\end{equation}&lt;/script&gt;			
可以应用R语言中的STL函数方便得到时间序列的各个成分以及异常点。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Forecast
这是一个R语言预测包，由澳大利亚的$Monash$大学的$Rob\ Hyndman$教授于2007年实现的。
这里主要举一个多周期傅里叶谐波回归的例子：
&lt;code class=&quot;highlighter-rouge&quot;&gt;r
msts_data&amp;lt;- msts(x, seasonal.periods=c(7,365)
msts_predict &amp;lt;- forecast(fit, xreg=fourier(msts_data, K=c(3,10), h=120))
&lt;/code&gt;
其中$K$指定的为提取的傅里叶谐波级数，$h$为预测的时间跨度，具体理论可以参考&lt;a href=&quot;https://robjhyndman.com/hyndsight/seasonal-periods/&quot;&gt;Seasonal periods&lt;/a&gt;。
&amp;gt; 实际应用过程中需要注意如下几点：&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;关于frequency的设置
 对于一个时间序列$ts$,如果没有制定freq参数，则会认为无周期项。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;异常点检测
 时间序列可能存在异常数据，STL分解时会除了返回各个构成项之外，同时返回各个时间点的权重，如果权重特别小，例如低于$10^{-6}$,表明该点在局部加权回归中意义不大，通常可以认为是异常点。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;facebook&quot;&gt;Facebook&lt;/h3&gt;
&lt;p&gt;在2017年2月份，Facebook宣布开源一款基于Python和R语言的时间序列预测工具$Prophet$,取“先知”之意。$Prophet$相比于现有预测工具更加人性化，并且同时支持Python和R语言，这一点尤其难能可贵，其项目主页&lt;a href=&quot;&quot;&gt;&lt;/a&gt;以及论文&lt;a href=&quot;&quot;&gt;&lt;/a&gt;。其中的”at scale”表明作者的初衷是想帮助大量的分析师在大量的场景和业务解决数据的预测。
$Prophet$的出发点是将时间序列分解成趋势项、周期项，同时考虑了节假日以及潜在突变量的影响。
&lt;script type=&quot;math/tex&quot;&gt;y(t)=g(t)+s(t)+h(t)+\epsilon_t \tag{65}&lt;/script&gt;
针对趋势项$g(t)$，表征的是时间序列的长期趋势，$Prophet$提供了两种典型的增长函数：
- 线性：
&lt;script type=&quot;math/tex&quot;&gt;g(t)=kt+b  \tag{66}&lt;/script&gt;
- 非线性：
&lt;script type=&quot;math/tex&quot;&gt;g(t)=\dfrac{C}{1+exp(-k(t-b))}  \tag{67}&lt;/script&gt;
进一步考虑到业务数据可能会由于业务本身版本发布、重大事件等因素，以致于序列数据短期内发展趋势有所变化，$Prophet$为此引入了“转变点”（$change\ point$），目的是自动检测趋势的变化，表达式分别如下：
- 线性：
&lt;script type=&quot;math/tex&quot;&gt;g(t)=(k+a(t)^T\delta)+(b+a(t)^T\gamma)  \tag{68}&lt;/script&gt;
- 非线性：
&lt;script type=&quot;math/tex&quot;&gt;g(t)=\dfrac{C(t)}{1+exp(-(k+a(t)^T\delta)(t-(b+a(t)^T)\gamma))} \tag{69}&lt;/script&gt;
另外业务数据在每年中的各个月份、每周中的各天、全年的各个节假日都会有不同的表现，$Prophet$通过采用傅里叶谐波级数来表达每年各个月波动以及每周中的各天波动，通过虚拟变量(dummy variables)来处理用户自己设置的重要节日，表达式分别如下：
- 线性：
&lt;script type=&quot;math/tex&quot;&gt;y(t)=(k+a(t)^T\delta)+(b+a(t)^T\gamma)+X\beta+\epsilon_t \tag{70}&lt;/script&gt;
- 非线性：
&lt;script type=&quot;math/tex&quot;&gt;y(t)=\dfrac{C(t)}{1+exp(-(k+a(t)^T\delta)(t-(b+a(t)^T)\gamma))}+X\beta+\epsilon_t \tag{71}&lt;/script&gt;
其中各个变量分别表示：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;变量&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;维度大小&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;含义&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$t$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1*T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;代表时间序列数据，总长度为T&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$k$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1*1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;实数，表示增长率&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$b$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1*1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;实数，表示截距&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$\delta$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;S*1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;向量，表示增长率的变化&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$\gamma$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;S*1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;向量，表示截距的变化&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$a$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;T*S&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;矩阵，表示序列趋势的回归系数&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$\beta$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;K*1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;向量，表示周期项以及节假日项回归系数&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$X$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;T*K&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;矩阵，表示周期项以及节假日项目的矩阵&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$\epsilon$&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;T*1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;向量，表示模型拟合残差&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;$Prophet$结合先验知识，假设数据服从线性或非线性两种似然函数（likelihood function），另外对参数$k,b,\delta,\beta,\epsilon$也给以先验分布假设，通过最大后验证估计来得到满足当前假设的最有参数，从而进行预估。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;实际应用过程中需要注意如下几点：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- Capacity的选择

需要结合实际业务数据设置，如果设置过大，预估数据会偏高。

- 节假日的设置

需要分析节假日属性，一般相同属性的节日归为一类，例如在视频播放数据中，除夕播放量低，暑期开学低，可以归为一类；国庆节播放量大，可以设为另一类。还要注意节假日的持续时间长度设置。

- 长期误差与短期误差

如果考虑了长周期，则长期预估误差通常低于其他算法，然而在短期预估方面，效果一般。这个主要是由于该算法在考虑了week周期来刻画每周的变化规律，但是没有考虑自回归的影响。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;总之，$Prophet$一方面简单易用，一方面由于考虑了很多先验假设，因此需要先分析实际业务数据的一些特性，例如趋势、周期特性等，再应用其来预估，往往会达到更好的预估效果。&lt;/p&gt;

&lt;h3 id=&quot;ensemble&quot;&gt;Ensemble&lt;/h3&gt;
&lt;p&gt;针对同一个时间序列，从信息论的角度看，好的模型应该是能够完全提取序列的潜在模式，如内在的趋势、周期变化规律以及节假日的影响等，分解之后的残差服从高斯分布。同时，这个模型应该没有因为模式和参数的先验假设或者优化求解过程而产生过拟合。那么，该模型一般可以比较好的预测未来。然而，具体业务时间数据可能存在某种波动，单一模型不能有效把握，则需要同时考虑多个模型集成，往往可以获得更加鲁棒的预估性能。&lt;/p&gt;

&lt;h2 id=&quot;section-15&quot;&gt;下一步工作&lt;/h2&gt;
&lt;p&gt;本文所述时间序列分析理论和方法依然更多关注序列本身，关注如何充分挖掘当前序列的信息，然而实际时间序列本身是一个不断演进的过程，就模型而言，还可以应用条件异方差自回归模型$GARCH$来刻画模型，或者考虑应用小波变换来提取时间序列的波动性。更重要的是，时间序列的演进还有很多外在因素，如何引入外在因素，如舆情指数、多个时间变量相关性等进一步提升预估准确率，提前发现并预警预估误差波动过大的缘由，依然需要更进一步深入分析。&lt;/p&gt;

&lt;h2 id=&quot;section-16&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;林尽水源，便得一山，山有小口，仿佛若有光。&lt;/p&gt;

&lt;h2 id=&quot;section-17&quot;&gt;致谢&lt;/h2&gt;
&lt;p&gt;感谢各位同事参与讨论指导。&lt;/p&gt;

&lt;h2 id=&quot;section-18&quot;&gt;参考文献&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://facebook.github.io/prophet/&quot;&gt;$Prophet$&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.rdocumentation.org/packages/bsts/versions/0.7.1/topics/bsts&quot;&gt;$bsts(Bayesian\ Structual\ Time\ Series)$&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/twitter/AnomalyDetection&quot;&gt;$Anomaly\ Detection$&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Netflix/Surus&quot;&gt;$Robust\ Anomaly\ Detection$&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cs.nyu.edu/~mohri/talks/NIPSTutorial2016.pdf&quot;&gt;$DBP(Discrepancy\ based\ Forecast)$&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.otexts.org/fpp/6/1&quot;&gt;$《Forecasting: principles and practice - Rob \ J.\  Hyndman$》&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;《金融时间序列分析-蔡瑞胸》&lt;/li&gt;
  &lt;li&gt;《量化投资-以Python为工具-蔡立耑》&lt;/li&gt;
  &lt;li&gt;《时间序列分析-汉密尔顿》&lt;/li&gt;
  &lt;li&gt;《数学物理方法-胡学刚》&lt;/li&gt;
  &lt;li&gt;《数学分析-陈传璋》&lt;/li&gt;
  &lt;li&gt;《信号与系统-郑君里》&lt;/li&gt;
  &lt;li&gt;《数字信号处理-程培青》&lt;/li&gt;
  &lt;li&gt;《通信原理-周炯槃》&lt;/li&gt;
  &lt;li&gt;《Pattern Recognition and Machine Learning- Christopher Bishop 》&lt;/li&gt;
  &lt;li&gt;《The Elements of Statistical Learning-Trevor Hastie》&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.bioinf.jku.at/publications/older/2604.pdf&quot;&gt;《Long short-term memory》&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://zacklipton.com/media/papers/recurrent-network-review-lipton-2015v2.pdf&quot;&gt;《A Critical Review of Recurrent Neural Networks for Sequence Learning》&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs&quot;&gt;Understanding LSTM - Colah&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/c/web-traffic-time-series-forecasting&quot;&gt;Web Traffic Time Series Forecasting-Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 11 Nov 2017 11:31:28 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/timeseries/2017/11/11/timeseries-TimeSeriesAnalysis.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/timeseries/2017/11/11/timeseries-TimeSeriesAnalysis.html</guid>
        
        
        <category>timeseries</category>
        
      </item>
    
      <item>
        <title>统计学简史</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;历史回顾&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;整体框架&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;描述统计&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;推断统计&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;面向未来&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-6&quot; id=&quot;markdown-toc-section-6&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;2014年10月份，杜博士在推荐中心的群里给大家推荐周希儒院士的《统计学简史》，大家群情高涨，就一起买了这本书，有些人将其放置案头以供瞻仰而并不曾深入完整阅读，我就是其中一人。这三年，心中一直记得这件事要完成，终于找了一个周末，读完了这本书。有些思考和感悟，整理于此！&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;历史回顾&lt;/h2&gt;

&lt;h2 id=&quot;section-2&quot;&gt;整体框架&lt;/h2&gt;

&lt;h2 id=&quot;section-3&quot;&gt;描述统计&lt;/h2&gt;

&lt;h2 id=&quot;section-4&quot;&gt;推断统计&lt;/h2&gt;

&lt;h2 id=&quot;section-5&quot;&gt;面向未来&lt;/h2&gt;

&lt;h2 id=&quot;section-6&quot;&gt;总结&lt;/h2&gt;
</description>
        <pubDate>Fri, 11 Aug 2017 10:32:28 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/math/2017/08/11/The-concise-history-of-Statistics.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/math/2017/08/11/The-concise-history-of-Statistics.html</guid>
        
        
        <category>math</category>
        
      </item>
    
      <item>
        <title>深度学习之一:Caffe环境搭建</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;为什么会有问题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;有哪些依赖库&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#anacondapython&quot; id=&quot;markdown-toc-anacondapython&quot;&gt;安装Anaconda配置Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#caffe&quot; id=&quot;markdown-toc-caffe&quot;&gt;下载Caffe&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cudnn-acceleration-switch-uncomment-to-build-with-cudnn&quot; id=&quot;markdown-toc-cudnn-acceleration-switch-uncomment-to-build-with-cudnn&quot;&gt;cuDNN acceleration switch (uncomment to build with cuDNN).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cpu-only-switch-uncomment-to-build-without-gpu-support&quot; id=&quot;markdown-toc-cpu-only-switch-uncomment-to-build-without-gpu-support&quot;&gt;CPU-only switch (uncomment to build without GPU support).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uncomment-to-disable-io-dependencies-and-corresponding-data-layers&quot; id=&quot;markdown-toc-uncomment-to-disable-io-dependencies-and-corresponding-data-layers&quot;&gt;uncomment to disable IO dependencies and corresponding data layers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uncomment-to-allow-mdbnolock-when-reading-lmdb-files-only-if-necessary&quot; id=&quot;markdown-toc-uncomment-to-allow-mdbnolock-when-reading-lmdb-files-only-if-necessary&quot;&gt;uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uncomment-if-youre-using-opencv-3&quot; id=&quot;markdown-toc-uncomment-if-youre-using-opencv-3&quot;&gt;Uncomment if you’re using OpenCV 3&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#to-customize-your-choice-of-compiler-uncomment-and-set-the-following&quot; id=&quot;markdown-toc-to-customize-your-choice-of-compiler-uncomment-and-set-the-following&quot;&gt;To customize your choice of compiler, uncomment and set the following.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cuda-directory-contains-bin-and-lib-directories-that-we-need&quot; id=&quot;markdown-toc-cuda-directory-contains-bin-and-lib-directories-that-we-need&quot;&gt;CUDA directory contains bin/ and lib/ directories that we need.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cuda-architecture-setting-going-with-all-of-them&quot; id=&quot;markdown-toc-cuda-architecture-setting-going-with-all-of-them&quot;&gt;CUDA architecture setting: going with all of them.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#blas-choice&quot; id=&quot;markdown-toc-blas-choice&quot;&gt;BLAS choice:&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#homebrew-puts-openblas-in-a-directory-that-is-not-on-the-standard-search-path&quot; id=&quot;markdown-toc-homebrew-puts-openblas-in-a-directory-that-is-not-on-the-standard-search-path&quot;&gt;Homebrew puts openblas in a directory that is not on the standard search path&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#note-this-is-required-only-if-you-will-compile-the-python-interface&quot; id=&quot;markdown-toc-note-this-is-required-only-if-you-will-compile-the-python-interface&quot;&gt;NOTE: this is required only if you will compile the python interface.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uncomment-to-use-python-3-default-is-python-2&quot; id=&quot;markdown-toc-uncomment-to-use-python-3-default-is-python-2&quot;&gt;Uncomment to use Python 3 (default is Python 2)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#we-need-to-be-able-to-find-libpythonxxso-or-dylib&quot; id=&quot;markdown-toc-we-need-to-be-able-to-find-libpythonxxso-or-dylib&quot;&gt;We need to be able to find libpythonX.X.so or .dylib.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#homebrew-installs-numpy-in-a-non-standard-path-keg-only&quot; id=&quot;markdown-toc-homebrew-installs-numpy-in-a-non-standard-path-keg-only&quot;&gt;Homebrew installs numpy in a non standard path (keg only)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uncomment-to-support-layers-written-in-python-will-link-against-python-libs&quot; id=&quot;markdown-toc-uncomment-to-support-layers-written-in-python-will-link-against-python-libs&quot;&gt;Uncomment to support layers written in Python (will link against Python libs)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#whatever-else-you-find-you-need-goes-here&quot; id=&quot;markdown-toc-whatever-else-you-find-you-need-goes-here&quot;&gt;Whatever else you find you need goes here.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#if-homebrew-is-installed-at-a-non-standard-location-for-example-your-home-directory-and-you-use-it-for-general-dependencies&quot; id=&quot;markdown-toc-if-homebrew-is-installed-at-a-non-standard-location-for-example-your-home-directory-and-you-use-it-for-general-dependencies&quot;&gt;If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#nccl-acceleration-switch-uncomment-to-build-with-nccl&quot; id=&quot;markdown-toc-nccl-acceleration-switch-uncomment-to-build-with-nccl&quot;&gt;NCCL acceleration switch (uncomment to build with NCCL)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uncomment-to-use-pkg-config-to-specify-opencv-library-paths&quot; id=&quot;markdown-toc-uncomment-to-use-pkg-config-to-specify-opencv-library-paths&quot;&gt;Uncomment to use &lt;code class=&quot;highlighter-rouge&quot;&gt;pkg-config&lt;/code&gt; to specify OpenCV library paths.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#nb-both-build-and-distribute-dirs-are-cleared-on-make-clean&quot; id=&quot;markdown-toc-nb-both-build-and-distribute-dirs-are-cleared-on-make-clean&quot;&gt;N.B. both build and distribute dirs are cleared on &lt;code class=&quot;highlighter-rouge&quot;&gt;make clean&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uncomment-for-debugging-does-not-work-on-osx-due-to-httpsgithubcombvlccaffeissues171&quot; id=&quot;markdown-toc-uncomment-for-debugging-does-not-work-on-osx-due-to-httpsgithubcombvlccaffeissues171&quot;&gt;Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#the-id-of-the-gpu-that-make-runtest-will-use-to-run-unit-tests&quot; id=&quot;markdown-toc-the-id-of-the-gpu-that-make-runtest-will-use-to-run-unit-tests&quot;&gt;The ID of the GPU that ‘make runtest’ will use to run unit tests.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#enable-pretty-build-comment-to-see-full-commands&quot; id=&quot;markdown-toc-enable-pretty-build-comment-to-see-full-commands&quot;&gt;enable pretty build (comment to see full commands)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;相关知识点&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[TOC]
## 前言
深度学习突破了以往的统计学习方法，虽然目前理论还不明朗，但是着实在很多领域取得了一些阶段性的成果，例如Google的机器翻译、百度的自动驾驶、腾讯的智慧医疗、科大讯飞的语音识别等，引领者新的浪潮。深度学习的工具方面，有Caffe、Tensorflow、Theano、Keras等。网络上流传一张图，如下：
&lt;img src=&quot;/img/caffe_install.jpg&quot; alt=&quot;caffe&quot; /&gt;&lt;/p&gt;

&lt;p&gt;经过查证，&lt;a href=&quot;https://www.imooc.com/article/1370&quot;&gt;Lecun&lt;/a&gt;应该没有转推过上图，不过从图中看，Caffe安装的价格最高的，可以看出即使深度学习已经成为一个“地摊”术语，Caffe安装这第一步还是比较重要的。最近结合Caffe，应用深度学习研究广告素材的优化，最开始在环境搭建上面走了一些弯路，为了避免后续再次入坑，简略记录下。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;为什么会有问题&lt;/h2&gt;
&lt;p&gt;主要是各个用户机器环境、软件版本(Centos、Ubuntu及其衍生版)都有差异，与官网不一定一致。Caffe安装使用会涉及一些依赖，例如Opencv、Python等，另外编译安装时会涉及一些动态链接库的知识等。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;有哪些依赖库&lt;/h2&gt;
&lt;p&gt;主要依赖为Opencv(图像处理)、Boost（例如可以提供python接口)、Protobuf（定义网络结构层）等。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo yum install protobuf-devel leveldb-devel snappy-devel opencv-devel boost-devel hdf5-devel gflags-devel glog-devel lmdb-devel
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;anacondapython&quot;&gt;安装Anaconda配置Python&lt;/h2&gt;
&lt;p&gt;通过Anaconda可以方便配置各种需要的环境（例如python 3）需要的依赖。&lt;/p&gt;

&lt;h2 id=&quot;caffe&quot;&gt;下载Caffe&lt;/h2&gt;
&lt;p&gt;在github下载源代码，地址为：
https://github.com/BVLC/caffe
## 编译配置
编译caffe常见有两种方式，分别是直接修改makefile和cmake。这里介绍第一种：
&lt;code class=&quot;highlighter-rouge&quot;&gt;shell
cd caffe
cp Makefile.config.example Makefile.config
vim Makefile.config
&lt;/code&gt;
Makefile.config里面有依赖库的路径，及各种编译配置，如果是没有GPU的情况下，可以参照我下面帮你改的配置文件内容:
```shell
## Refer to http://caffe.berkeleyvision.org/installation.html
# Contributions simplifying and improving our build system are welcome!&lt;/p&gt;

&lt;h1 id=&quot;cudnn-acceleration-switch-uncomment-to-build-with-cudnn&quot;&gt;cuDNN acceleration switch (uncomment to build with cuDNN).&lt;/h1&gt;
&lt;p&gt;# USE_CUDNN := 1&lt;/p&gt;

&lt;h1 id=&quot;cpu-only-switch-uncomment-to-build-without-gpu-support&quot;&gt;CPU-only switch (uncomment to build without GPU support).&lt;/h1&gt;
&lt;p&gt;CPU_ONLY := 1  如果硬件限制，只需要编译cpu版本&lt;/p&gt;

&lt;h1 id=&quot;uncomment-to-disable-io-dependencies-and-corresponding-data-layers&quot;&gt;uncomment to disable IO dependencies and corresponding data layers&lt;/h1&gt;
&lt;p&gt;# USE_OPENCV := 0
# USE_LEVELDB := 0
# USE_LMDB := 0&lt;/p&gt;

&lt;h1 id=&quot;uncomment-to-allow-mdbnolock-when-reading-lmdb-files-only-if-necessary&quot;&gt;uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)&lt;/h1&gt;
&lt;p&gt;#	You should not set this flag if you will be reading LMDBs with any
#	possibility of simultaneous read and write
# ALLOW_LMDB_NOLOCK := 1&lt;/p&gt;

&lt;h1 id=&quot;uncomment-if-youre-using-opencv-3&quot;&gt;Uncomment if you’re using OpenCV 3&lt;/h1&gt;
&lt;p&gt;# OPENCV_VERSION := 3&lt;/p&gt;

&lt;h1 id=&quot;to-customize-your-choice-of-compiler-uncomment-and-set-the-following&quot;&gt;To customize your choice of compiler, uncomment and set the following.&lt;/h1&gt;
&lt;p&gt;# N.B. the default for Linux is g++ and the default for OSX is clang++
# CUSTOM_CXX := g++&lt;/p&gt;

&lt;h1 id=&quot;cuda-directory-contains-bin-and-lib-directories-that-we-need&quot;&gt;CUDA directory contains bin/ and lib/ directories that we need.&lt;/h1&gt;
&lt;p&gt;CUDA_DIR := /usr/local/cuda  如果有cuda可以加速计算，这里实际没有用
# On Ubuntu 14.04, if cuda tools are installed via
# “sudo apt-get install nvidia-cuda-toolkit” then use this instead:
# CUDA_DIR := /usr&lt;/p&gt;

&lt;h1 id=&quot;cuda-architecture-setting-going-with-all-of-them&quot;&gt;CUDA architecture setting: going with all of them.&lt;/h1&gt;
&lt;p&gt;# For CUDA &amp;lt; 6.0, comment the *_50 through *_61 lines for compatibility.
# For CUDA &amp;lt; 8.0, comment the *_60 and *_61 lines for compatibility.
# For CUDA &amp;gt;= 9.0, comment the *_20 and *_21 lines for compatibility.
CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \
		-gencode arch=compute_20,code=sm_21 \
		-gencode arch=compute_30,code=sm_30 \
		-gencode arch=compute_35,code=sm_35 \
		-gencode arch=compute_50,code=sm_50 \
		-gencode arch=compute_52,code=sm_52 \
		-gencode arch=compute_60,code=sm_60 \
		-gencode arch=compute_61,code=sm_61 \
		-gencode arch=compute_61,code=compute_61&lt;/p&gt;

&lt;h1 id=&quot;blas-choice&quot;&gt;BLAS choice:&lt;/h1&gt;
&lt;p&gt;# atlas for ATLAS (default)
# mkl for MKL
# open for OpenBlas
#BLAS := atlas
BLAS := open  blas作为矩阵计算的方式，常见有三种，openblas是其中一种开源免费的库，可以通过yum安装
# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.
# Leave commented to accept the defaults for your choice of BLAS
# (which should work)!
# BLAS_INCLUDE := /path/to/your/blas
# BLAS_LIB := /path/to/your/blas&lt;/p&gt;

&lt;h1 id=&quot;homebrew-puts-openblas-in-a-directory-that-is-not-on-the-standard-search-path&quot;&gt;Homebrew puts openblas in a directory that is not on the standard search path&lt;/h1&gt;
&lt;p&gt;# BLAS_INCLUDE := $(shell brew –prefix openblas)/include
# BLAS_LIB := $(shell brew –prefix openblas)/lib&lt;/p&gt;

&lt;p&gt;BLAS_INCLUDE := /usr/include/openblas
# This is required only if you will compile the matlab interface.
# MATLAB directory should contain the mex binary in /bin.
# MATLAB_DIR := /usr/local
# MATLAB_DIR := /Applications/MATLAB_R2012b.app&lt;/p&gt;

&lt;h1 id=&quot;note-this-is-required-only-if-you-will-compile-the-python-interface&quot;&gt;NOTE: this is required only if you will compile the python interface.&lt;/h1&gt;
&lt;p&gt;# We need to be able to find Python.h and numpy/arrayobject.h.
#PYTHON_INCLUDE := /usr/include/python2.7 \
#		/usr/lib/python2.7/dist-packages/numpy/core/include
#PYTHON_INCLUDE := /usr/local/bin/pyt/include/python2.7/ \
		/usr/lib64/python2.7/site-packages/numpy/core/include
# Anaconda Python distribution is quite popular. Include path:
# Verify anaconda location, sometimes it’s in root.
ANACONDA_HOME := $(HOME)/anaconda2   注意HOME的路径 与sudo有关
PYTHON_INCLUDE := $(ANACONDA_HOME)/include \
		 $(ANACONDA_HOME)/include/python2.7 \
		 $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include&lt;/p&gt;

&lt;h1 id=&quot;uncomment-to-use-python-3-default-is-python-2&quot;&gt;Uncomment to use Python 3 (default is Python 2)&lt;/h1&gt;
&lt;p&gt;# PYTHON_LIBRARIES := boost_python3 python3.5m
# PYTHON_INCLUDE := /usr/include/python3.5m \
#                 /usr/lib/python3.5/dist-packages/numpy/core/include&lt;/p&gt;

&lt;h1 id=&quot;we-need-to-be-able-to-find-libpythonxxso-or-dylib&quot;&gt;We need to be able to find libpythonX.X.so or .dylib.&lt;/h1&gt;
&lt;p&gt;#PYTHON_LIB := /usr/lib
#PYTHON_LIB := /usr/local/lib
PYTHON_LIB := $(ANACONDA_HOME)/lib&lt;/p&gt;

&lt;h1 id=&quot;homebrew-installs-numpy-in-a-non-standard-path-keg-only&quot;&gt;Homebrew installs numpy in a non standard path (keg only)&lt;/h1&gt;
&lt;p&gt;# PYTHON_INCLUDE += $(dir $(shell python -c ‘import numpy.core; print(numpy.core.&lt;strong&gt;file&lt;/strong&gt;)’))/include
# PYTHON_LIB += $(shell brew –prefix numpy)/lib&lt;/p&gt;

&lt;h1 id=&quot;uncomment-to-support-layers-written-in-python-will-link-against-python-libs&quot;&gt;Uncomment to support layers written in Python (will link against Python libs)&lt;/h1&gt;
&lt;p&gt;WITH_PYTHON_LAYER := 1&lt;/p&gt;

&lt;h1 id=&quot;whatever-else-you-find-you-need-goes-here&quot;&gt;Whatever else you find you need goes here.&lt;/h1&gt;
&lt;p&gt;INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib&lt;/p&gt;

&lt;h1 id=&quot;if-homebrew-is-installed-at-a-non-standard-location-for-example-your-home-directory-and-you-use-it-for-general-dependencies&quot;&gt;If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies&lt;/h1&gt;
&lt;p&gt;# INCLUDE_DIRS += $(shell brew –prefix)/include
# LIBRARY_DIRS += $(shell brew –prefix)/lib&lt;/p&gt;

&lt;h1 id=&quot;nccl-acceleration-switch-uncomment-to-build-with-nccl&quot;&gt;NCCL acceleration switch (uncomment to build with NCCL)&lt;/h1&gt;
&lt;p&gt;# https://github.com/NVIDIA/nccl (last tested version: v1.2.3-1+cuda8.0)
# USE_NCCL := 1&lt;/p&gt;

&lt;h1 id=&quot;uncomment-to-use-pkg-config-to-specify-opencv-library-paths&quot;&gt;Uncomment to use &lt;code class=&quot;highlighter-rouge&quot;&gt;pkg-config&lt;/code&gt; to specify OpenCV library paths.&lt;/h1&gt;
&lt;p&gt;# (Usually not necessary – OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)
# USE_PKG_CONFIG := 1&lt;/p&gt;

&lt;h1 id=&quot;nb-both-build-and-distribute-dirs-are-cleared-on-make-clean&quot;&gt;N.B. both build and distribute dirs are cleared on &lt;code class=&quot;highlighter-rouge&quot;&gt;make clean&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;BUILD_DIR := build
DISTRIBUTE_DIR := distribute&lt;/p&gt;

&lt;h1 id=&quot;uncomment-for-debugging-does-not-work-on-osx-due-to-httpsgithubcombvlccaffeissues171&quot;&gt;Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171&lt;/h1&gt;
&lt;p&gt;# DEBUG := 1&lt;/p&gt;

&lt;h1 id=&quot;the-id-of-the-gpu-that-make-runtest-will-use-to-run-unit-tests&quot;&gt;The ID of the GPU that ‘make runtest’ will use to run unit tests.&lt;/h1&gt;
&lt;p&gt;TEST_GPUID := 0&lt;/p&gt;

&lt;h1 id=&quot;enable-pretty-build-comment-to-see-full-commands&quot;&gt;enable pretty build (comment to see full commands)&lt;/h1&gt;
&lt;p&gt;Q ?= @&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;可以看出每个路径配置的方法都有多种方法，可以实际“坑”去google搜索解决。这里有一个有意思的是，sudo make和make编译和运行结果是不一样的，主要是由于HOME目录差异。

## 编译caffe
开启并行编译：
```shell
make -j4
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;可以测试下结果：
&lt;code class=&quot;highlighter-rouge&quot;&gt;shell
make test
make runtest
&lt;/code&gt;
## 编译pycaffe
&lt;code class=&quot;highlighter-rouge&quot;&gt;shell
make pycaffe -j4
&lt;/code&gt;
可以测试下python接口是否安装好：
&lt;code class=&quot;highlighter-rouge&quot;&gt;python
&amp;gt;&amp;gt;&amp;gt; import caffe
&lt;/code&gt;
如果没有报错则说明caffe可能安装好了。
## 应用caffe开发
caffe是否安装完成，是否能够支持引用开发，还需要进一步设置，例如
&lt;code class=&quot;highlighter-rouge&quot;&gt;shell
export CAFFE_ROOT=...
export LD_LIBRARY_PATH=...
&lt;/code&gt;
这里需要注意LD_LIBRARY_PATH中不要添加anaconda的路径，否则会&lt;a href=&quot;https://groups.google.com/forum/#!msg/caffe-users/wKYe45FKSqE/HcFMlGS-M8gJ&quot;&gt;libtiff报错&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;相关知识点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;LD_LIBRARY_PATH&lt;/li&gt;
  &lt;li&gt;PKG_CONFIG_PATH&lt;/li&gt;
  &lt;li&gt;动态链接库&lt;/li&gt;
  &lt;li&gt;makefile&lt;/li&gt;
  &lt;li&gt;gdb&lt;/li&gt;
  &lt;li&gt;rpm&lt;/li&gt;
  &lt;li&gt;tesseract&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;“工欲善其事，必先利其器”。caffe是深度学习在图像领域广泛使用的框架，其model zoo有大量的预训练好的模型提供使用。大部分图像相关的应用部分将用到caffe。如何进一步挖掘caffe中的模型实现方法，高效完成个性化的需求是一个重要的方向。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;参考文献&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://coldmooon.github.io/2015/07/09/caffe/&quot;&gt;Caffe 安装错误记录及解决办法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zybuluo.com/hanxiaoyang/note/364680&quot;&gt;linux(CentOS)下的caffe编译安装简易手册&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://gist.github.com/arundasan91/b432cb011d1c45b65222d0fac5f9232c&quot;&gt;caffe install&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 12 Mar 2017 21:12:06 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/deeplearning/2017/03/12/DeepLearning-Caffe-install.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/deeplearning/2017/03/12/DeepLearning-Caffe-install.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>攻略推荐流程简介</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;业务简介&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;主要内容&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;攻略特征生成&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;数据源准备&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;数据源&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#xml&quot; id=&quot;markdown-toc-xml&quot;&gt;如何从xml网页文档提取中文&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;构建词库&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#section-6&quot; id=&quot;markdown-toc-section-6&quot;&gt;分词与自定义字典&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#section-7&quot; id=&quot;markdown-toc-section-7&quot;&gt;词性过滤&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-8&quot; id=&quot;markdown-toc-section-8&quot;&gt;攻略关键词提取&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#tf-idf&quot; id=&quot;markdown-toc-tf-idf&quot;&gt;$TF-IDF$关键词提取原理&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#section-9&quot; id=&quot;markdown-toc-section-9&quot;&gt;具体实现&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dummy&quot; id=&quot;markdown-toc-dummy&quot;&gt;离散Dummy化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#tcaplus&quot; id=&quot;markdown-toc-tcaplus&quot;&gt;生成特征并写入Tcaplus&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-10&quot; id=&quot;markdown-toc-section-10&quot;&gt;用户特征生成&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-11&quot; id=&quot;markdown-toc-section-11&quot;&gt;用户自然人属性计算&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dummy-1&quot; id=&quot;markdown-toc-dummy-1&quot;&gt;离散Dummy化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#tcaplus-1&quot; id=&quot;markdown-toc-tcaplus-1&quot;&gt;生成特征并写入Tcaplus&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-12&quot; id=&quot;markdown-toc-section-12&quot;&gt;配置攻略和用户交叉属性&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#storm&quot; id=&quot;markdown-toc-storm&quot;&gt;Storm实时统计与样本拼接&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#storm-1&quot; id=&quot;markdown-toc-storm-1&quot;&gt;什么是Storm&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-13&quot; id=&quot;markdown-toc-section-13&quot;&gt;日志接入与样本拼接&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-14&quot; id=&quot;markdown-toc-section-14&quot;&gt;样本拼接&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-15&quot; id=&quot;markdown-toc-section-15&quot;&gt;逻辑回归模型训练&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#ml&quot; id=&quot;markdown-toc-ml&quot;&gt;最大似然法ML&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#map&quot; id=&quot;markdown-toc-map&quot;&gt;最大后验估计MAP与正则化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-16&quot; id=&quot;markdown-toc-section-16&quot;&gt;在线训练&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-17&quot; id=&quot;markdown-toc-section-17&quot;&gt;参数调优&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-18&quot; id=&quot;markdown-toc-section-18&quot;&gt;效果对比&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-19&quot; id=&quot;markdown-toc-section-19&quot;&gt;贝叶斯平滑&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-20&quot; id=&quot;markdown-toc-section-20&quot;&gt;推荐系统&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#epr&quot; id=&quot;markdown-toc-epr&quot;&gt;EPR报表生成&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-21&quot; id=&quot;markdown-toc-section-21&quot;&gt;监控告警&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-22&quot; id=&quot;markdown-toc-section-22&quot;&gt;待优化点&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-23&quot; id=&quot;markdown-toc-section-23&quot;&gt;致谢&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-24&quot; id=&quot;markdown-toc-section-24&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;业务简介&lt;/h2&gt;
&lt;p&gt;我们最近针对掌盟和王者荣耀手机助手等应用App，提供个性化的游戏攻略推荐，在优化用户体验中作了一些尝试。在游戏攻略推荐过程中，用户和攻略的信息作为预测的特征。预测的过程可以看成一个二分类的问题，即计算用户对攻略的感兴趣程度。本文将主要从工程和理论两个角度简要介绍处理流程。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;主要内容&lt;/h2&gt;
&lt;p&gt;介绍攻略和用户属性的特征工程处理&lt;/p&gt;

&lt;p&gt;介绍基于Tdbank和Storm的实时处理系统&lt;/p&gt;

&lt;p&gt;介绍逻辑回归和基于Spark的模型训练&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;攻略特征生成&lt;/h2&gt;

&lt;h3 id=&quot;section-3&quot;&gt;数据源准备&lt;/h3&gt;

&lt;h4 id=&quot;section-4&quot;&gt;数据源&lt;/h4&gt;
&lt;p&gt;一般各个项目组的游戏攻略存储都有差异，例如有放在cdb中或者redis中。攻略推荐的原始数据主要需要下面几个字段：攻略标识、中文标题、作者、攻略内容、发布时间、播放次数（例如视频攻略）等其他字段。攻略内容大都以原始的xml形式，例如：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;&amp;lt;strong style=&quot;white-space: normal;&quot;&amp;gt;&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;——&amp;lt;/strong&amp;gt;解析&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;1.线上续航能力神技能，配合上出门装多兰盾，还有防御天赋的两点“愈合”，你就知道前期的德玛西亚之力盖伦有多恶心人了！&amp;lt;br/&amp;gt;&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;2.如果对拼大亏后，果断舍弃补兵，躲草丛吃经验，一分钟后又是一个名扬天下的草丛伦！&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;xml&quot;&gt;如何从xml网页文档提取中文&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from bs4 import BeautifulSoup
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个库可以有效提取xml网页中的中文，在爬虫中比较常用。提取中文之后如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;——解析 1.线上续航能力神技能，配合上出门装多兰盾，还有防御天赋的两点“愈合”，你就知道前期的德玛西亚之力盖伦有多恶心人了！    2.如果对拼大亏后，果断舍弃补兵，躲草丛吃经验，一分钟后又是一个名扬天下的草丛伦！
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section-5&quot;&gt;构建词库&lt;/h4&gt;
&lt;p&gt;分别为作者、标题、内容构建词库，为后期的关键词dummy化特征作准备。&lt;/p&gt;

&lt;h4 id=&quot;section-6&quot;&gt;分词与自定义字典&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://www.oschina.net/p/jieba&quot;&gt;Jieba&lt;/a&gt;分词简单易用，效率高。在利用Jieba分词时，需要预先加载一个自定义分词字典。这个字段主要包括英雄的称号、名字、技能、符文、天赋以及常见的游戏解说名字等。例如如下自定义字典:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;德玛西亚
盖伦
草丛伦
多兰盾
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在分词之前预加载自定义的字典，则可以保持“草丛伦”不会被分成“草丛”和“伦”。
另外需要注意的是，例如在LOL中的英雄盖伦，盖伦是名字，德玛西亚是称号，草丛伦是外号，这个都应被判定为盖伦。&lt;/p&gt;

&lt;h4 id=&quot;section-7&quot;&gt;词性过滤&lt;/h4&gt;
&lt;p&gt;分词之后需要对词性进行标注并进行词性过滤。&lt;/p&gt;

&lt;p&gt;词性标注如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import jieba.posseg as pseg
words =pseg.cut(&quot;线上续航能力神技能，配合上出门装多兰盾，还有防御天赋的两点“愈合”，你就知道前期的德玛西亚之力盖伦有多恶心人了!如果对拼大亏后，果断舍弃补兵，躲草丛吃经验，一分钟后又是一个名扬天下的草丛伦！&quot;,HMM=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;对于词性过滤一般要求如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;对分词结果，删除停用词、频繁无用词、单字词，只保留以下词性的词语：
（1）名词类：n（名词），nr（人名），ns（地名），nt（机构团体名），nz（其他专用名），ng（名词性词素）
（2）动词类：v（动词），vn（名动词），vl（动词性惯用语），vg（动词性语素）
（3）形容词类：a（形容词），an（名形词），ag（形容词性语素），al（形容词性惯用语）
（4）英文：eng（英文）
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;最后会剩下以下词语:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;续航 能力 技能 配合 出门 多兰盾 还有 防御 天赋 愈合 知道 德玛西亚 盖伦 恶心
舍弃 补兵 草丛 经验 草丛伦
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;实践过程中需要注意到unicode、utf8以及gbk等编码之间的转化&lt;/p&gt;

&lt;h3 id=&quot;section-8&quot;&gt;攻略关键词提取&lt;/h3&gt;
&lt;p&gt;经过上面的分词和词性过滤，每篇攻略正文内容将过滤得到比较重要的词语，接下来需要对几千篇有效攻略进行分析，应用$TF-IDF$来提取每篇攻略的关键词。&lt;/p&gt;

&lt;h4 id=&quot;tf-idf&quot;&gt;$TF-IDF$关键词提取原理&lt;/h4&gt;
&lt;p&gt;$TF-IDF$($Term\ frequency-inverse\ document\ frequency$ ) 是文本挖掘中一种广泛使用的特征向量化方法。&lt;/p&gt;

&lt;p&gt;假设单词用$t$表示，文档用$d$表示，语料用$D$表示，那么文档频度$DF(t,D)$是包含单词$t$的文档数。如果我们只是使用词频度量重要性，就会很容易过分强调重复次数多但携带信息少的单词，例如：“a”,“the”以及“of”。如果某个单词在整个语料库中高频出现，意味着它没有携带专门针对某特殊文档的信息。&lt;/p&gt;

&lt;p&gt;其中词频$TF$指的是某一个给定的词语在该文件中出现的次数。$TF$通常要被归一化（区别于下面的$IDF$，分子小于分母）：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;TF(t,d) = \frac{t}{d}  \tag{1}&lt;/script&gt;

&lt;p&gt;逆文档频度$IDF$是单词携带信息量的数值度量:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;IDF(t,D) = \log \frac{|D| + 1}{DF(t,D) + 1} \tag{2}&lt;/script&gt;

&lt;p&gt;其中是$\lvert D \rvert$语料中的文档总数。由于使用了$log$计算，如果单词在所有文档中出现，那么$IDF$就等于0。注意这里做了平滑处理（+1操作），防止单词没有在语料中出现时IDF计算中除0。$TF-IDF$ 度量是$TF$和$IDF$的简单相乘：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;TFIDF(t,d,D) = TF(t,d) \cdot IDF(t,D) \tag{3}&lt;/script&gt;

&lt;p&gt;可以看出，$TF-IDF$与一个词在文档中的出现次数成正比，与该次在整个语料中的出现次数成反比。所以自动提取关键词的算法就是计算出文档的每个词的$TF-IDF$值，然后按照降序排列，取排在最前面的几个词。&lt;/p&gt;

&lt;h4 id=&quot;section-9&quot;&gt;具体实现&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from  sklearn import feature_extraction
from  sklearn.feature_extraction.text import TfidfTransformer
from  sklearn.feature_extraction.text import CountVectorizer
vectorizer=CountVectorizer(min_df=0.005,max_df=0.6)
transformer=TfidfTransformer()
tfidf=transformer.fit_transform(vectorizer.fit_transform(Corpus))
word=vectorizer.get_feature_names()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;经过$TF-IDF$之后，我们会为每一篇攻略内容保留至多10个关键词。关键词在词库索引中查找对应的编号，则每篇攻略就由不超过10个关键词的索引构成，例如某篇攻略关键词提取之后包含“多兰盾  防御  盖伦”，则根据词库可能会被编码类似于“237 896  145”。具体$TF-IDF$计算时需要注意设置合适的文档频DF阈值。&lt;/p&gt;

&lt;h3 id=&quot;dummy&quot;&gt;离散Dummy化&lt;/h3&gt;
&lt;p&gt;离散dummy化可以让模型保持一定的鲁棒性。上面得到每篇攻略的关键词索引可以直接Dummy化。然而每篇攻略上线之后的统计数据，例如点击率、播放次数等特征则需要进行离散Dummy化，具体公式如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;id=\dfrac{x_i-x_{min}}{x_{max}-x_{min}}*dummyRange \tag{4}&lt;/script&gt;

&lt;h3 id=&quot;tcaplus&quot;&gt;生成特征并写入Tcaplus&lt;/h3&gt;
&lt;p&gt;TCaplus是互娱研发部结合游戏特点、平衡性能和成本，开发的一款高速分布式Key-Values模型的NoSql存储系统。与之类似的是Redis，这是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库。&lt;/p&gt;

&lt;p&gt;这里用来给后面Storm实时拼接样本以及在线推荐系统提供高速存储。key是每篇游戏攻略的id，value是在稀疏特征空间的位置编号以及对应取值。&lt;/p&gt;

&lt;h2 id=&quot;section-10&quot;&gt;用户特征生成&lt;/h2&gt;

&lt;h3 id=&quot;section-11&quot;&gt;用户自然人属性计算&lt;/h3&gt;
&lt;p&gt;构建用户自然人属性宽表 ，主要包括用户基本信息、登录、活跃、付费、最近常玩英雄以及实力表现等数据，其中一部分数据可以来自例行化的用户画像数据。用户自然人属性和攻略属性的差异在于，基本来自结构化的数据处理，不再需要通过分析xml内容去提取关键词特征。&lt;/p&gt;

&lt;h3 id=&quot;dummy-1&quot;&gt;离散Dummy化&lt;/h3&gt;
&lt;p&gt;将之前的宽表各个字段根据要求分别进行离散Dummy化。例如用户的年龄和注册时间等，&lt;/p&gt;

&lt;h3 id=&quot;tcaplus-1&quot;&gt;生成特征并写入Tcaplus&lt;/h3&gt;
&lt;p&gt;类似攻略属性。&lt;/p&gt;

&lt;h2 id=&quot;section-12&quot;&gt;配置攻略和用户交叉属性&lt;/h2&gt;
&lt;p&gt;一般而言，一篇攻略包含作者、标题关键词、内容关键词、点击率等特征。同时每个用户则包含如基本信息、最近常用英雄、常失败英雄等上千维特征。这些攻略和用户特征既包含离散化特征，也有Dummy特征，需要具体制定哪些特征需要进行交叉，增强模型的解释能力。&lt;/p&gt;

&lt;h2 id=&quot;storm&quot;&gt;Storm实时统计与样本拼接&lt;/h2&gt;

&lt;h3 id=&quot;storm-1&quot;&gt;什么是Storm&lt;/h3&gt;
&lt;p&gt;Storm是一个开源、分布式、高容错的实时计算系统。Storm令持续不断的流计算变得容易，弥补了Hadoop批处理所不能满足的实时要求。Storm经常用于在实时分析、在线机器学习、持续计算、分布式远程调用和ETL等领域。Storm的部署管理非常简单，而且，在同类的流式计算工具，Storm的性能也是非常出众的。&lt;/p&gt;

&lt;p&gt;Storm主要分为两种组件Nimbus和Supervisor。这两种组件都是快速失败的，没有状态。任务状态和心跳信息等都保存在Zookeeper上的，提交的代码资源都在本地机器的硬盘上。&lt;/p&gt;

&lt;p&gt;Storm的常见关键词简介如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Storm提交运行的程序称为Topology。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Nimbus负责在集群里面发送代码，分配工作给机器，并且监控状态。全局只有一个。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Supervisor会监听分配给它那台机器的工作，根据需要启动/关闭工作进程Worker。每一个要运行Storm的机器上都要部署一个。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Zookeeper是Storm重点依赖的外部资源。Nimbus和Supervisor甚至实际运行的Worker都是把心跳保存在Zookeeper上的。Nimbus也是根据Zookeerper上的心跳和任务运行状况，进行调度和任务分配的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Topology处理的最小的消息单位是一个Tuple，也就是一个任意对象的数组。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Topology由Spout和Bolt构成，统称为Component。Spout是发出Tuple的结点,可以通过bid从tdbank中消费数据。Bolt可以随意订阅某个Spout或者Bolt发出的Tuple。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section-13&quot;&gt;日志接入与样本拼接&lt;/h3&gt;
&lt;p&gt;一方面由于客户端上报给我们的日志可能有多种形式，例如Probuf、Json或者Tlog等形式，另一方面由于考虑到后面Storm的处理能力，例如节假日一般数倍于平时的日志量。我们通过几乎透明的中转把数据发送到Tdbank（类似Kafka）它既可以起到后面缓冲消费的作用，并且可以将数据共享给其他合作的业务部门消费，起到了充分利用数据的目的。&lt;/p&gt;

&lt;p&gt;接下来通过Storm来消费Tdbank 的数据，主要有以下几个目的：&lt;/p&gt;

&lt;p&gt;1、PV和UV统计：主要包括曝光、点击的用户数据&lt;/p&gt;

&lt;p&gt;2、Filter：这个主要是用来在业务上线或者调试时，方便对关注的用户进行过滤，校验数据协议的准确性&lt;/p&gt;

&lt;p&gt;3、Sample：这个是用来拼接模型训练样本，每条样本包括用户特征、广告特征以及交叉特征&lt;/p&gt;

&lt;p&gt;4、Save：对部分数据保存至tdw，方便后续的深入分析&lt;/p&gt;

&lt;p&gt;更加深入的可以参考我的同事文章&lt;a href=&quot;http://km.oa.com/group/25372/articles/show/232795&quot;&gt;《图灵系统介绍（十）- 实时日志处理平台》&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-14&quot;&gt;样本拼接&lt;/h3&gt;
&lt;p&gt;LR模型比较简单，需要交叉特征提升模型表达能力。
在前面已经将用户属性和攻略属性分别离散Dummy化存储至KV系统Tcaplus，在拼接样本的bolt中，对来自spout的每条点击流数据判断是曝光还是点击，如果是点击则标记为正样本，否则为负样本。接下来对该条数据的uin去缓存查有无该用户数据，没有则至Tcaplus中去查询用户数据，得到uin的特征之后则查询攻略的特征，也是优先从缓存去查，然后去Tcaplus查询特征，接下来根据高阶交叉规则拼接模型样本。&lt;/p&gt;

&lt;p&gt;大部分情况下，待推荐的有效攻略不过几千，而用户量是远大于攻略数目的，例如掌盟的日均曝光UV可达500万，所以实际情况下，每条点击流数据主要是去Tcaplus去查询用户特征，而攻略特征在bolt运行一段时间之后大部分已经保存在Cache中。&lt;/p&gt;

&lt;p&gt;这里还要注意一点，在机器学习的模型训练中，正负样本的比例控制很重要。点击流中的曝光，也就是负样本远比正样本多，所以对负样本要做一定的筛选，使正负样本比例在一个合理的阈值范围之内，保证模型训练的有效性。&lt;/p&gt;

&lt;h2 id=&quot;section-15&quot;&gt;逻辑回归模型训练&lt;/h2&gt;
&lt;p&gt;在计算广告中，常使用逻辑回归模型，因为LR模型比较简单，易于大规模并行化。另外需要注意在特征工程中关注有效提取特征，特征的维度如果过高，后续的计算复杂度将会提高，需要考虑正则化。&lt;/p&gt;

&lt;h3 id=&quot;ml&quot;&gt;最大似然法ML&lt;/h3&gt;
&lt;p&gt;逻辑回归其实仅为在线性回归的基础上，套用了一个逻辑函数，但也就由于这个逻辑函数，逻辑回归成为了机器学习领域一颗耀眼的明星，更是计算广告学的核心。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} &amp; y=f(x)=w^Tx\tag{5} \\ &amp; y=f(x)=sign(w^Tx)\tag{6} \\ &amp; y=f(x)=\dfrac{1}{1+\exp(-w^Tx)}\tag{7} \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;假设$x\in R^d$  为$d$维输入向量，$y\in {0,1}$为输出标签，$w\in R^d$是参数。
 则有&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} &amp; p(y_i=1|x_i,w)=\dfrac{\exp(w^Tx)}{1+\exp(w^Tx)}=P_i\tag{8} \\ &amp; p(y_i=0|x_i,w)=\dfrac{1}{1+\exp(w^Tx)}=1-P_i \tag{9} \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;然后有：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} &amp; w^*=arg \  \underset{w}{max}P(D|w)\tag{10} \\ &amp;\hspace {6mm}  =arg \  \underset{w}{max}\prod_{i=1}^NP_i^{y_i}(1-P_i)^{1-y_i} \tag{11} \\ &amp; \hspace {6mm}  =arg \ \underset{w}{max}\sum_{i=1}^Ny_i\log{P_i}+(1-y_i)\log{(1-P_i)} \tag{12} \\ &amp; \hspace {6mm}  =arg \  \underset{w}{max}\sum_{i=1}^Ny_i\log{\dfrac{P_i}{1-P_i}}+\log{(1-P_i)} \tag{13} \\ &amp; \hspace {6mm}  =arg \  \underset{w}{max}=\sum_{i=1}^N[y_i\cdot w^Tx_i-\log{(1+\exp{(w^Tx_i)})}] \tag{14} \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;据Andrew Ng关于最大似然函数与最小损失函数的关系: 
\begin{align}
 &amp;amp;  J(w)=-\dfrac{1}{m}L(w) \tag{15}&lt;br /&gt;
\end{align}
 这里取:
\begin{align}
 &amp;amp;  J(w)=-L(w)=-\sum_{i=1}^N[y_i\cdot w^Tx_i-\log{(1+\exp{(w^Tx_i)})}] \tag{16}&lt;br /&gt;
\end{align}
 因此&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} &amp; \frac{\partial{J(w)}}{\partial{w}}=-\sum_{i=1}^N[y_i\cdot x_i-\dfrac{\exp{(w^Tx_i)}}{1+\exp{(w^Tx_i})}\cdot{x_i}]\tag{17} \\ &amp; \hspace {16mm} =\sum_{i=1}^N(P_i-y_i)\cdot{x_i}  \tag{18} \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;因此有参数的迭代如下：
 \begin{align}
&amp;amp; w_{j+1}=w_j-\alpha\cdot\sum_{i=1}^N(P_i-y_i)\cdot{x_i}  \tag{19}
\end{align}&lt;/p&gt;

&lt;h3 id=&quot;map&quot;&gt;最大后验估计MAP与正则化&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/&quot;&gt;《数学之美番外篇：平凡而又神奇的贝叶斯方法》&lt;/a&gt;形象的介绍过结合先验分布的最大后验估计。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} &amp; p(w|D)=\dfrac{p(w,D)}{p(D)} \\ &amp; \hspace {16mm}=\dfrac{p(D|w) \cdot p(w)}{p(D)} \\ &amp; \hspace {16mm}  \propto p(w) \cdot p(D|w) \tag{20} \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;假设模型的参数$w$服从分布$p(w)$,根据MAP则有：
 &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align} &amp; w^*=arg \  \underset{w}{max}P(w|D)  \\ &amp; \hspace {6mm}  = arg \  \underset{w}{max}P(w|D) \cdot P(D) \\ &amp; \hspace {6mm}  = arg \  \underset{w}{max}P(D|w) \cdot P(w) \\ &amp; \hspace {6mm}  = arg \  \underset{w}{max}[\log{P(D|w)} +\log{P(w)}]\tag{21}  \end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;对比ML和MAP推导的结果，可以看出MAP比ML多了$\log p(w)$，这个可以用来惩罚过拟合。根据奥卡姆剃刀原则，如果两个模型有着相似的解释能力，那就选择更简单的那个。也就是希望更多的$w$，取值为0,。更简单的模型还同时可以降低在线推荐server负担。实践当中一般有L1正则化和L2正则化两种。具体如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/prml-lr.png&quot; alt=&quot;prml&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图是我之前阅读&lt;a href=&quot;http://item.jd.com/19347236.html&quot;&gt;《Pattern Recognition and Machine Learning》&lt;/a&gt;  和 &lt;a href=&quot;http://item.jd.com/1132486430.html&quot;&gt;《The Elements of Statistical Learning》&lt;/a&gt;部分内容做的笔记。右上角就是我们常见的逻辑回归算法正则化以及对应的解法优化。&lt;/p&gt;

&lt;h3 id=&quot;section-16&quot;&gt;在线训练&lt;/h3&gt;
&lt;p&gt;Spark是在hadoop基础上改进得到的分布式框架，采用内存迭代式的计算，非常适合机器学习算法。相比于之前的map -reduce，spark提供了丰富的操作算子，以前我们可能需要编写很多代码，现在只需要通过若干个transform和action就可以完成。一般认为，hadoop特点在于批处理，storm特点在于流处理，spark特点在于内存迭代。我们在游戏攻略推荐中，用户属性生成和入库有着数量较大和周期性的特点，适合采用mapreduce；攻略效果统计和模型样本拼接对实时性要求较高，适合采用storm；在模型训练阶段涉及到多轮参数寻优迭代，适合采用spark。&lt;/p&gt;

&lt;h3 id=&quot;section-17&quot;&gt;参数调优&lt;/h3&gt;
&lt;p&gt;一方面，我们需要关注模型在测试集上的预测性能，例如准确率、召回率、AUC等，另一方面需要防止过拟合，调整损失函数和正则化之间的比例。训练得到的非零参数如果过多，则也不利于后期的在线推荐部分的计算。&lt;/p&gt;

&lt;p&gt;需要注意的是，一般用户和攻略的一阶特征可能不是太多，但是他们之间的交叉特征可能比较多，导致每条样本的维度比较高，模型训练的计算量也会比较大。后期可能会对特征交叉的规模有所折衷。&lt;/p&gt;

&lt;h3 id=&quot;section-18&quot;&gt;效果对比&lt;/h3&gt;
&lt;p&gt;上面的工作目的都只有一个，把合适的内容推荐给用户，提高点击率。一般我们把请求服务器的用户分成一定比例的对照用户，对比算法的实际效果。典型的例如在算法、强规则、随机包、热销榜之间的点击流对比。&lt;/p&gt;

&lt;p&gt;随机包就是指用户请求我们时，随机推荐攻略给用户；&lt;/p&gt;

&lt;p&gt;强规则在各个业务中有所差异，例如在掌盟中将用户最近对局常失败的英雄对应的攻略推荐给用户；&lt;/p&gt;

&lt;p&gt;热销榜则是根据最近12小时内的攻略点击率排行榜给用户推荐，热销榜具有很强的时效性，另外需要衡量点击率的指标需要略做优化。例如攻略A的曝光量是200，点击量是100，点击率是50%；同时攻略B的曝光量是2000，而点击量是900，点击率是45%，攻略A和B该怎么排序？这个也是需要注意的。&lt;/p&gt;

&lt;h3 id=&quot;section-19&quot;&gt;贝叶斯平滑&lt;/h3&gt;
&lt;p&gt;预估互联网广告的点击率一个重要的技术手段是logistic regression 模型，这个模型非常依赖特征的设计。每个广告的反馈ctr作为特征能极大地提升预估的准确性，所以每个广告的反馈ctr非常重要。
目前用得比较多的获取反馈ctr的方式是直接计算每个广告的历史ctr，这样的问题就是当该广告投放量比较少的时候（如新广告），历史ctr与实际ctr相差很大。如一个广告投放了100次，有2次点击，那么ctr就是2%，但是当这个广告投放量到了1000次的时候，点击只有10次，点击率是1%，这里就相差了一倍了。产生这种问题的的原因是投放量太少，数据有偏，所以如果每个广告在开始投放前就有了默认的一个展示数和点击数，即分子分母都加上一个比较大的常数，这样计算起ctr来就不会有那么大的偏差。这种方法叫做ctr平滑，通用的方法是在展示数和点击上面各自加一个常数，缓解低投放量带来的不准确性，使其接近其实际的CTR。&lt;/p&gt;

&lt;h2 id=&quot;section-20&quot;&gt;推荐系统&lt;/h2&gt;
&lt;p&gt;实时在线推荐系统方面，我的同事在&lt;a href=&quot;http://km.oa.com/group/25372/articles/show/238608&quot;&gt;《游戏广告推荐服务器原理介绍和实现总结》&lt;/a&gt;中形象的介绍了实现的流程，在与推荐系统对接时，需要添加一些人工规则，例如最近的攻略，或者对模型的参数进行变化，来降低实时推荐系统的计算压力。能离线计算好的部分尽量先行计算，然后异步更新到Cache中，方便后续的计算、排序和推荐。&lt;/p&gt;

&lt;h3 id=&quot;epr&quot;&gt;EPR报表生成&lt;/h3&gt;
&lt;p&gt;EPR是互娱运营部数据中心推出的一套报表系统，旨在通过在EPR配置端创建报表和配置报表参数，可以将结构化的数据转换成成可视化报表并展现给用户。通过对报表页参数不同的配置，用户可以在浏览器中看到丰富的报表展现形式，如折线图、柱状图、表格等。具体使用方法可以参考&lt;a href=&quot;http://km.oa.com/group/18997/articles/show/220812?kmref=search&amp;amp;from_page=1&amp;amp;no=2&amp;amp;is_from_iso=1&quot;&gt;《使用“TDW+洛子系统+EPR”完成数据展示》&lt;/a&gt;。可以方便的展示算法的效果。&lt;/p&gt;

&lt;h3 id=&quot;section-21&quot;&gt;监控告警&lt;/h3&gt;

&lt;p&gt;本文简要介绍的游戏攻略推荐，在实践中，当这些前后依赖的任务建立起来之后，需要设置一定的告警环节，保证任务之间可靠运行，发现问题能够尽快解决。可以申请微信告警账号进行监控各项指标是否异常。&lt;/p&gt;

&lt;h2 id=&quot;section-22&quot;&gt;待优化点&lt;/h2&gt;
&lt;p&gt;1、一方面目前任务处理较长。用户属性是洛子调度写入tdw，然后出库至hdfs，配置mapreduce命令行进行离散化和dummy化并生成用户特征，然后批量写入tcaplus。由于用户量通常比较大，计算任务之间的依赖在洛子调度的时延可能会被放大，后面计划将用户属性部分改成spark来计算。&lt;/p&gt;

&lt;p&gt;2、其次针对攻略属性的特征提取。在利用$TF-IDF$进行关键词提取时，还有很多细节需要把握。&lt;/p&gt;

&lt;p&gt;3、还有考虑其他模型。为了实现了解用户、推荐出合适的攻略，本文介绍的是“折腾特征”的方法，也就是模型想对简单。然而另外一个思路就是“折腾模型”，也就是不去根据经验和实践对特征进行很多离散、 dummy 化以及交叉等操作，直接将可能包含连续取值的原始数据直接交给深度学习模型，去进行预测点击率。&lt;/p&gt;

&lt;h2 id=&quot;section-23&quot;&gt;致谢&lt;/h2&gt;
&lt;p&gt;本文提及的攻略推荐工作是在数据挖掘组很多同事大量前期工作和丰富经验的基础上才得以完成。主要是在杜博、caron、sophie和woli等的帮助和指导下，不断发现和解决一个又一个细节问题。总结本文的目的在于梳理工作、找出潜在问题并推广至其他的业务。&lt;/p&gt;

&lt;h2 id=&quot;section-24&quot;&gt;参考文献&lt;/h2&gt;
&lt;p&gt;[1、&lt;a href=&quot;http://km.oa.com/knowledge/2074&quot;&gt;《图灵系统文集》&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 05 Aug 2016 11:31:28 +0800</pubDate>
        <link>http://sigmajiangcn.github.io/adrecommend/2016/08/05/adrecommend-gamesadrecommend.html</link>
        <guid isPermaLink="true">http://sigmajiangcn.github.io/adrecommend/2016/08/05/adrecommend-gamesadrecommend.html</guid>
        
        
        <category>adRecommend</category>
        
      </item>
    
  </channel>
</rss>
